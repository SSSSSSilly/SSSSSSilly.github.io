<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>My New Post</title>
      <link href="/2024/04/21/my-new-post/"/>
      <url>/2024/04/21/my-new-post/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/04/21/hello-world/"/>
      <url>/2024/04/21/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>CONNECTING LARGE LANGUAGE MODELS WITH EVOLUTIONARY ALGORITHMS YIELDS POWERFUL PROMPT OPTIMIZERS</title>
      <link href="/2024/04/21/connecting-large-language-models-with-evolutionary-algorithms-yields-powerful-prompt-optimizers/"/>
      <url>/2024/04/21/connecting-large-language-models-with-evolutionary-algorithms-yields-powerful-prompt-optimizers/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><strong>ABSTRACT：</strong><br />大型语言模型（llm）在各种任务中表现出色，但它们依赖于精心制作的提示，而这往往需要大量的人力努力。为了自动化这一过程，在本文中，我们提出了一个新的离散提示优化框架，称为诱发提示，它借鉴了进化算法（EAs）的思想，因为它们表现出良好的性能和快速的收敛速度。为了使EAs能够处理离散的提示，这是一种需要连贯的、具有人类可读性的自然语言表达式，我们将llm与EAs联系起来。这种方法允许我们同时利用llm强大的语言处理能力和EAs的高效优化性能。具体来说，去掉任何梯度或参数，诱发提示从提示种群开始，基于进化操作符使用llm迭代生成新的提示，基于开发集改进种群。我们在31个数据集上，优化了包括GPT-3.5和Alpaca在内的封闭和开源llm的提示，包括语言理解、生成任务以及BIG-Bench Hard（BBH）任务。诱发提示的性能显著优于人工工程提示和现有的自动提示生成方法（例如，在BBH上高达25%）。此外，evo提示法还表明，将llm与EAs连接起来可以产生协同效应，这可以启发对llm与传统算法结合的进一步研究。</p><p><strong>Introduction：</strong><br />大型语言模型（LLMs）在多种自然语言处理（NLP）任务上表现出显著的表现。为了适应下游任务，只需在输入文本中添加一条指令，也称为离散提示符，即可引导llm执行所需的任务，而对计算成本的影响可以忽略不计。这种方法还消除了对llm中所有参数和梯度的需要，使其适用于具有api的llm，如GPT-3和GPT-4。尽管方便，LLMs对特定任务的表现受到提示的显著影响。因此，这种方法的关键挑战在于提示工程的设计，这已成为一种被称为提示工程的关键技术。鉴于不同语言模型和任务之间的提示符差异很大，提示性设计通常需要大量的人力努力和专业知识，以及主观的和相对有限的指导方针。<br />为了减轻人类在离散提示设计上的努力，以前的方法通常依赖于从llm的输出层访问token概率，这可能并不总是可以通过api访问。最近的一些工作考虑列举不同的提示并选择最好的提示，或修改当前的提示来改进它们，这些方法要么强调探索不同的提示，这可能导致优柔寡断和浪费资源，要么专注于利用当前确定的好提示，这可能导致停滞，并将搜索限制在局部最优。几种传统的无导数算法设计良好，在勘探和开发之间取得了良好的平衡。其中，进化算法（EAs）因其简单、高效、适合离散即时优化而突出，提示中的短语序列可以看作是典型EAs中的基因序列，使其与自然进化过程相容。<br />在本文中，我们借用了EAs的思想，并提出了一个离散的提示调优框架，即诱发提示。虽然EAs中的进化操作符通常是为序列而设计的，但它们倾向于独立地改变标记，以生成新的候选解决方案。不幸的是，这种方法忽略了令牌之间的连接，而这对于保持提示中的一致性和可读性至关重要。利用<strong>LLMs在NLP方面的专业知识和EAs的特殊优化能力，我们将这两种方法连接起来，其中LLMs根据进化操作符生成新的候选提示</strong>，而EAs指导优化过程以保留最优提示。<br />具体来说，基于几个初始提示，我们利用llm作为进化操作符来生成新的提示候选符，并保留了在开发集上具有更好性能的提示。对更新种群进行上述操作的迭代应用，以提高质量。通过精心设计进化算符和调整更新策略，可以用各种类型的EAs来实例化诱发提示。我们优化了两个不同的llm的提示，包括不同范围的神经语言理解和生成任务，以及具有挑战性的BBH任务，使用总共31个数据集。与人工设计的提示和以前的自动提示生成方法相比，诱发提示始终能得到更好的提示。</p><p><strong>Contributions：</strong><br />1、我们提出了一种新的连接llm和EAs的自动离散提示优化框架，称为evople提示，它具有以下优点： 1)不需要访问llm的任何参数或梯度；2)它在探索和开发之间取得平衡，从而获得更好的结果；3)生成的提示是人类可读的。<br />2、在31个数据集上进行的实验表明，与精心制作的提示以及现有的方法相比，诱发提示的有效性。针对情绪分类、主题分类、主观性分类、简化、总结和推理等常见任务，我们发布了通过诱发提示得到的最优提示。<br />3、我们证明了llm能够实现提供适当指令的多种类型的EAs。我们希望我们的探索将激发对llm与传统算法结合的进一步研究，为llm的新应用和创新应用铺平道路。</p><p><strong>Related Works：</strong><br /><strong>Prompts in LLMs ：</strong>提示法是在特定任务中使用llm的一种有效方法。然而，性能受到提示符的选择的严重影响。近年来，自动提示优化得到了广泛的关注。基于提示的连续方法，仅调整某些输入token的参数引起了大量关注。尽管这些范式具有有效的性能，但它们的两个缺点不容忽视： 1)连续提示的优化需要黑盒api无法访问的llmam参数。2)软提示往往缺乏可解释性。离散提示，简单地添加几个离散的标记，如“It是”，或特定于任务的描述性指令，如“将评论分为积极或消极”。，可以为输入文本提供一个交互界面，具有更好的可解释性的人，并在各种NLP任务中显示出良好的性能。<br /><strong>Discrete Prompts ：</strong>已经提出了各种方法来自动离散提示搜索和生成，而这些方法仍然依赖于输出层的梯度或标记概率。最近，考虑到下游任务中不同提示的高方差，一些工作集中于通过从一些候选提示中列举和选择最佳提示，主要通过重新抽样来增强。基于提示编辑的方法强调开发，这可能会导致局部优化。另一种方法是收集错误预测的案例，并分析相应的根本原因，以改进现有的提示，这也强调了开发利用。此外，这些方法被限制为具有标准答案的任务，不能直接应用于生成任务。我们提出的具有进化算法的诱发提示在不需要任何参数或梯度的情况下，在探索和开发之间取得平衡。<br /><strong>LLMs and Optimization Algorithms ：</strong>llm显示了作为黑盒优化器的潜力；然而，这种黑盒方法缺乏可解释性。一些研究表明，llm有能力模仿传统算法中的特定操作。例如，llm可以通过收集错误预测的样本，在离散空间中执行“梯度下降”。同时，已经证明LLMs可以模仿遗传算法（GA）中的突变或交叉操作符。Chen等人进一步集成了llm和GA用于神经结构搜索，而Lanzi&amp;Loiocono也引入了类似的游戏设计方法。我们的工作向前迈出了重要的一步，提出了一个将llm与进化算法连接起来的通用框架，该框架可以通过定制进化和选择过程实例化到不同的进化算法，从而扩大其在该领域的适用性和潜在影响。我们渴望这项工作，以激发结合llm和传统算法的更广泛的应用。</p><p><strong>Method：</strong><br />自动离散提示优化：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710506620383-e6d16375-8dbf-44d1-9feb-80505930527c.png#averageHue=%23f5f2ee&clientId=u691cf207-c476-4&from=paste&height=263&id=udc03198c&originHeight=263&originWidth=606&originalType=binary&ratio=1&rotation=0&showTitle=false&size=63318&status=done&style=none&taskId=ued03b702-ef4e-47eb-b562-90aa2a157e9&title=&width=606" alt="a3610b0c52927f0b76ec7865abd546c.png"><br />当前的高级llm通常通过黑盒api进行交互，而梯度和参数是不可访问的。进化算法（EAs）是一种无导数的算法，具有特殊的精度和快速的收敛性。因此，我们考虑在离散即时优化中引入EAs。然而，为了生成新的候选解决方案，进化操作符通常会独立地编辑当前解决方案中的元素，而不考虑它们之间的连接。这使得在离散提示上应用进化操作符具有挑战性，因为这需要一致性和可读性。为了解决这一挑战，我们提出了一种协同的方法，将llm的自然语言处理专业知识与EAs的优化能力联系起来，称为诱发提示。具体来说，llm基于进化操作符生成新的候选提示，而EAs指导优化过程以找到最优提示。<br />为了在实践中实现诱发提示，有必要用一种特定的EAs算法对其进行实例化。EAs有各种各样的类型，在本文中，我们考虑了两种广泛使用的算法，包括遗传算法（GA）和微分进化（DE）。GA是最受重视的进化算法之一，DE自成立以来已成为复杂优化挑战的最广泛应用算法之一。下面，我们将首先概述所提出的诱发提示，然后分别用GA和DE实例化诱发提示。<br />FRAMEWORK OF EVOPROMPT：<br />EAs通常从N个解的初始种群开始（在我们的设置中是提示），然后在当前种群上使用进化算符（例如，突变和交叉）迭代生成新的解决方案，并基于适应度函数更新它。遵循典型的EAs，诱发提示主要包括三个步骤：<br /><strong>初始化种群：</strong>与大多数现有的忽略先验人类知识的自动提示方法相反，我们将可用的手动提示作为初始种群来利用人类的智慧。此外，EAs通常从随机解开始，导致一个多样化的种群，并避免陷入一个局部最优。因此，我们还在初始人群中引入了一些由llm生成的提示。<br /><strong>进化：</strong>在每次迭代中，诱发提示使用llm作为进化操作符，根据从当前总体中选择的几个父提示生成一个新的提示。为了实现这一点，我们为<strong>每个特定类型的EAs设计了突变和交叉操作符的步骤</strong>，以及相应的指令来指导llm基于这些步骤生成新的提示。<br /><strong>更新：</strong>我们在开发集上评估生成的候选提示，并保留那些具有优越性能的提示，类似于自然界中的适者生存。具体的更新策略可能会根据所使用的EAs的类型而有所不同。<br />当迭代的次数达到一个预定义的值时，该算法将停止。在算法1中概述了诱发提示的细节。当使用特定的EAs算法实例化诱发提示时，需要调整进化过程，而<strong>关键的挑战是在离散提示上设计进化操作符</strong>。<br />使用遗传算法的实例化：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710508611514-3a01ac47-64b1-471f-8678-6783b978bcf7.png#averageHue=%23f0ecea&clientId=u691cf207-c476-4&from=paste&height=449&id=u24115ea7&originHeight=449&originWidth=709&originalType=binary&ratio=1&rotation=0&showTitle=false&size=94250&status=done&style=none&taskId=u7528e358-0bcc-4585-ae86-6e3d4384da9&title=&width=709" alt="cc6f695c2af25c75ed55227095b56c0.png"><br />在遗传算法中，父解通常使用轮盘赌轮选择方法进行选择，并根据其适应度值进行指导。类似地，我们使用轮盘赌轮选择，从当前人群中选择两个父提示，基于他们在开发集中获得的性能分数。设si表示在包含N个提示的总体中，第i个提示的性能分数。选择第i个提示作为父提示的概率可以表示为<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710508524300-c28ed087-c827-49fa-9cc9-9594832a1240.png#averageHue=%23f6f3f0&clientId=u691cf207-c476-4&from=paste&height=25&id=u49c2bb45&originHeight=25&originWidth=117&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1920&status=done&style=none&taskId=u1d59634c-36db-40ec-a6df-5de42d7b52e&title=&width=117" alt="6fe89f7f3204b96ec3ff998b317f605.png">。<br />进化符合遗传算法框架，我们通过两个步骤生成一个新的候选提示： 1)在亲代提示之间进行交叉，产生一个新的后代提示；2)对子代提示进行突变，对某些元素引入随机改变。我们将这一两阶段的操作形式化为算法指令，以指导llm在算法1中实现Evo（·）。整个过程如图1所示。<br />我们采用了一种简单的选择策略来更新种群：在每次迭代中，诱发提示产生N个新的提示，这些提示与现有的N个提示的种群合并。随后，根据他们的分数，保留前N个提示，以形成更新的总体。因此，种群的整体质量不断提高，最终在最终种群中选择最好的一个作为最佳提示。<br />具有差异进化的实例化：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710508619667-d4d84473-8ede-442d-acfa-12609fc45c16.png#averageHue=%23f5f2ee&clientId=u691cf207-c476-4&from=paste&height=738&id=u34513b22&originHeight=738&originWidth=764&originalType=binary&ratio=1&rotation=0&showTitle=false&size=185261&status=done&style=none&taskId=u8b91dd0e-dddf-46f4-9350-817001aaff6&title=&width=764" alt="265a4ba8a718d660330e36f7fad1d93.png"><br />在这里，我们从对DE的一些初步知识开始。与遗传算法不同，DE的解用数值向量表示。种群中的每个向量依次选择为一个基向量，记为x，随后进行突变和交叉。在突变过程中，从当前种群中随机选择的方案a生成突变方案y。该突变是通过将两个不同的、随机选择的解决方案b和c之间的比例差添加到a中来实现的，即y&#x3D;a+F（b−c），其中F是比例参数。<br />交叉是通过从基本解x或突变解y中选择向量中的每个参数来生成一个试验解<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710508788944-9e4974a0-4dcd-4d38-be4b-c809c1e96b10.png#averageHue=%23f9f6f2&clientId=u691cf207-c476-4&from=paste&height=22&id=uc51ba1b6&originHeight=22&originWidth=112&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1301&status=done&style=none&taskId=uc949ff55-3884-4910-bfd8-ab4c83fa3b9&title=&width=112" alt="be2ebcf167bbd1fae5a76bc0c10c700.png">。然后，如果x‘比x好，则用x’代替x。在逐步的进化中，DE以一个高质量的种群结束。DE的一个修改版本使用当前的最佳解决方案作为向量a来利用来自最佳解决方案的信息。<br />DE的进化过程可以解耦为三个步骤： 1) F（b−c）；2) y &#x3D; a + F（b−c）；3)x和y的交叉。在基于DE的诱发提示中，我们遵循三个步骤来设计进化过程，以及llm根据这些步骤生成新提示的相应指令，如图2所示：<br />1、受DE中的微分向量的启发，我们考虑只改变当前种群中两个随机选择的两个提示的不同部分（图2中的步骤1和步骤2）。当前人群中的提示被认为是当前最好的提示。因此，两个提示的共享组件往往对性能有积极的影响，因此需要予以保留。<br />2、DE的一个变体在突变过程中使用了当前的最佳向量，其中通过将微分向量的规模添加到当前的最佳向量中来生成一个突变向量。在此基础上，我们通过选择性地将当前最好的部分替换为突变的不同部分，从而生成突变提示。（图2中的第3步）。<br />3、交叉将基本提示符中的某些组件（即当前总体的候选组件）替换为从突变提示符中获得的片段。此操作结合了两个不同提示的特性，可能会创建一个新的和改进的解决方案（图2中的步骤4）。<br />按照标准DE，当前总体中的每个提示pi被选择为基本提示，然后使用图2中的指令生成相应的新提示p’i 。然后，保留得分较高的提示符，或pi或p’i 。因此，种群规模保持不变，而种群的总体质量则有所提高。</p><p>Experiments：<br />通过GPT-3.5执行进化操作符，我们使用开源Alpaca-7b和闭源GPT-3.5（文本-达文奇-003年）的诱发提示来优化提示。我们选择在开发集上分数最高的提示符，并在测试集上报告其分数。对羊驼报告的结果在3个随机种子上进行平均，并提供了标准偏差，而对于GPT-3.5，由于预算限制，我们报告了一个种子的结果。在我们的评估中，我们比较了诱发提示与三类基于提示的方法，具体如下：<br />**Manual Instructions (MI)**：这些作为特定任务的指导方针，并基于已建立的工作制定，特别引用Zhang等人（2023b）用于语言理解，Sanh等人（2021）用于总结，Zhang等人（2023c）用于文本简化。<br /><strong>PromptSource</strong> and <strong>Natural Instructions (NI) <strong>：这些存储库聚合了跨不同数据集的人类组成的提示。<br /><strong>APE和APO</strong>：APE采用迭代蒙特卡罗搜索策略，强调探索。我们复制它，并初始化与诱发提示相同大小的种群。APO将错误预测的实例作为“伪梯度”来迭代地细化原始提示，这强调了开发。我们以最优手动提示作为初始提示，在二进制分类任务上重现APO。<br /><strong>语言理解：</strong><br />数据集和设置我们首先进行实验语言理解任务在7个数据集来验证我们的方法，包括情绪分类（SST-2，MR，CR，SST-5），主题分类(AG’s News，TREC和主观性分类）。为了约束输出标签空间，我们在测试用例之前准备每个类一个示例的演示。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710509481529-c845c34d-5505-4257-be6e-af8c552a4728.png#averageHue=%23f2f0ec&clientId=u691cf207-c476-4&from=paste&height=182&id=ua429fd27&originHeight=182&originWidth=699&originalType=binary&ratio=1&rotation=0&showTitle=false&size=49562&status=done&style=none&taskId=u404f4e72-8387-4dfa-b000-4b7cf2970ab&title=&width=699" alt="d081f7a15c4c0aaddd55a7572d3f09a.png"><br />主要结果表1显示： 1)与以往关于提示生成和人工书面指令的工作相比，基于GA和DE的诱发提示具有明显更好的效果。2)在情绪分类数据集上，诱发提示（GA）略优于诱发提示（DE）。当涉及到主题分类数据集时，evo提示符（DE）表现得更好。值得注意的是，在主观性分类任务（Subj）上，诱发提示符（DE）比其遗传算法有了很大的改进，获得了5%的准确率优势。这可能是由于当初始提示不是高质量时，DE逃避局部最优的特殊能力。<br /><strong>语言生成：</strong><br />数据集和设置为语言生成，我们评估我们的文本摘要和简化任务的诱发提示。对于总结，我们采用了SAMSum，这是一个具有挑战性和复杂的对话总结数据集，并报告了Alpaca-7b和GPT-3.5的ROUGE-1&#x2F;2&#x2F;L评分。为了简化文本，旨在在简化源文本的同时保留其原始含义，我们使用了资产数据集，这是一个以其多重参考翻译而闻名的基准。我们将SARI评分作为评价指标，这是一种基于n-gram的评分系统，广泛用于文本编辑任务。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710509489810-1c70b45f-b613-4a78-902f-834a2a5d22b4.png#averageHue=%23f2f0ed&clientId=u691cf207-c476-4&from=paste&height=194&id=u40252191&originHeight=194&originWidth=705&originalType=binary&ratio=1&rotation=0&showTitle=false&size=37845&status=done&style=none&taskId=u20961b4c-e65a-4a10-a59b-19576fa2c36&title=&width=705" alt="c2b28c31d02bded0917566552824b96.png"><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710509498414-54448374-d413-494c-b53b-7117cb79b077.png#averageHue=%23f2efed&clientId=u691cf207-c476-4&from=paste&height=186&id=ud31cc174&originHeight=186&originWidth=369&originalType=binary&ratio=1&rotation=0&showTitle=false&size=27756&status=done&style=none&taskId=u3a6f36d0-612b-4c3e-922d-652f2e9bdbe&title=&width=369" alt="cff41bb727ec4dc1675ae7b66e62339.png"><br />主要结果汇总和简化结果见表2和表3。与人工设计的提示相比，Evopnicte实现了显著的性能提高，在Alpaca和GPT-3.5 API上的SARI分数提高了3分以上。此外，在评估场景中始终优于APE方法，表明所生成的提示能够有效地利用llm的功能来获得卓越的性能。此外，在总结任务中，诱发提示（DE）明显优于诱发提示（GA），同时在文本简化任务中表现出类似的性能。这表明，DE变体对于诸如摘要等更复杂的语言生成任务特别有效。<br /><strong>BIG BENCH HARD (BBH)：</strong><br />为了验证在不同的任务上我们的方法，我们应用BBH，包括23个具有挑战性的任务，需要多步推理。由于这些任务具有挑战性，我们专注于优化GPT-3.5的提示。我们从测试集中抽取一个子集作为开发集，并报告标准化分数1，并与提示符“让我们一步一步地思考”进行比较。在测试集上进行3次思维链演示。我们使用任务id来简化每个任务的表示，并删除一个，因为手动提示的准确率已经达到100%。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710509663375-640c91a3-5785-4d83-b69f-c2242b225352.png#averageHue=%23f2ebe5&clientId=u691cf207-c476-4&from=paste&height=230&id=ue1fd40bb&originHeight=230&originWidth=705&originalType=binary&ratio=1&rotation=0&showTitle=false&size=26910&status=done&style=none&taskId=u4c9f1ca4-eac3-467e-81e9-85216462fdf&title=&width=705" alt="472abd2b2911b106ccb15ebe6079143.png"><br />evo提示符会为所有22个任务获得更好的提示（图3）。具体来说，诱发提示（DE）达到高达25%的改善，平均为3.5%，而诱发提示（GA）达到峰值为15%的改善，平均为2.5%。尽管对于某些任务，GA对应项的性能优于DE版本，但性能差距仍然相对较小（即约1%）。同时，在6个任务中，诱发提示（DE）超过诱发提示（GA）2%以上。因此，DE版本通常是处理这些具有挑战性的任务的一个很好的选择。<br />分析：<br />对于诱发提示（GA），我们默认应用轮盘赌轮选择策略来选择父母的提示，对后代有贡献。为了进一步探索各种选择策略的影响，我们将我们的方法与另外两种流行的策略进行了比较，即tournament和随机选择，如表4所示。我们观察到，使用轮盘赌轮的诱发提示（GA）获得了更高的分数，显示了这种选择方法的有效性。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710509751664-4e4f987e-b2e1-43cf-bedd-c9cd72eef722.png#averageHue=%23f1efec&clientId=u691cf207-c476-4&from=paste&height=144&id=uc055f76e&originHeight=144&originWidth=336&originalType=binary&ratio=1&rotation=0&showTitle=false&size=17714&status=done&style=none&taskId=u61c836b4-b5cd-4626-9c60-72202df3647&title=&width=336" alt="2eea901660e94f8df544eacc4d63d99.png"><br />对于evo提示（DE），我们深入研究了使DE的进化操作符适应离散提示时的两个关键设计考虑： 1)不同部分的突变，2)选择当前性能最好的提示作为图2中的“提示3”。我们评估了这些设计选择对两个数据集： Subj，一个理解数据集，其中evo提示（DE）优于evo提示（GA），和资产，一个生成数据集，其中两个变体表现出相似的性能。<br />为了说明只突变不同部分的好处，我们将图2中的前两个步骤替换为指令“随机突变提示1和提示2”，以允许对提示1和提示2中的所有内容发生突变，在表5中表示为“所有”。同时，诱发提示中的原始设计，只改变不同的部分，记为“差异”。如表5所示，仅在不同部分上进行突变设计可以在两个任务中一致地获得性能提高。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710509833110-cecd4ec7-5a5a-459c-a1ee-3e9d18d28090.png#averageHue=%23f1efec&clientId=u691cf207-c476-4&from=paste&height=149&id=ub4dd7bc0&originHeight=149&originWidth=357&originalType=binary&ratio=1&rotation=0&showTitle=false&size=19584&status=done&style=none&taskId=u96c6180d-d732-412d-b674-0b99e291ae7&title=&width=357" alt="d49f9767f57a8aea5e2ba4b69ac0f56.png"><br />在DE算法的诱发提示（DE）中应用DE算法的一个变体，我们在当前总体中选择最佳提示作为图2中的提示3。我们通过以下设置来验证这一设计： 1)提示3从当前人群中随机抽样，在表5中表示为“随机”；2)通过让基本提示直接跨越突变的不同部分来消除提示3的使用（即删除图2中的步骤3），在Tabel 5中表示为“消除”。表5清楚地说明了引入提示符3的重要性。此外，选择最佳提示作为提示3比随机抽样更有效。<br /><strong>总体初始化：</strong><br />我们研究了初始种群质量对诱发提示的影响。我们进行了试点实验，根据提示在开发集上的性能对提示进行排序（手动设计或由GPT-3.5生成）。然后，我们选择底部、随机和顶部的提示以及它们相应的变化作为初始提示。这些变化是使用Zhou等人（2022）设计的重采样模板生成的，如附录B.2中的图4所示，该模板用于为初始化引入随机性。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710509997042-dfab8a0e-58b4-4349-9591-8fee3639d019.png#averageHue=%23f5f2ed&clientId=u691cf207-c476-4&from=paste&height=171&id=u6b0546a7&originHeight=171&originWidth=310&originalType=binary&ratio=1&rotation=0&showTitle=false&size=16027&status=done&style=none&taskId=u069595aa-8a9a-4397-8b0f-137d74070ae&title=&width=310" alt="cdffd10747c28cdd11d6bc450e8ed09.png"><br />表6表明： 1)初始提示的</strong>精心设计并不必要</strong>，因为随机选择提示可以达到与选择性能最好的提示相似的性能；2)在选择性能最好的提示时，通过允许GPT-3引入随机性。产生变化可以导致整体性能的轻微提高；但是，当随机选择提示时，没有必要对诱发提示（DE）引入额外的随机性；3)当使用性能最好的初始提示时，诱发提示（GA）略优于诱发提示（DE）；但当从表现不佳的初始提示开始时，诱发提示（DE）优于诱发提示（GA），这表明当可用的手动提示质量不高时，DE是一个更好的选择。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1710510150158-5b499c3b-fbdc-4b8b-925a-8ce17dc113af.png#averageHue=%23f2efeb&clientId=u691cf207-c476-4&from=paste&height=273&id=u792d97f7&originHeight=273&originWidth=337&originalType=binary&ratio=1&rotation=0&showTitle=false&size=36516&status=done&style=none&taskId=u85237faa-3a0d-4acd-ac03-3bae38b2663&title=&width=337" alt="30b26d5a7af51b5464a044583ee8db2.png"><br /><strong>Conclusions：</strong><br />我们引入了诱发提示来优化离散提示，它将llm与进化算法连接起来。在31个数据集上的大量实验证明了诱发提示的优越性，比手动指令和现有方法产生一致的性能收益。此外，我们还验证了llm可以作为一个有效的、可解释的接口来实现遗传算法和DE等进化算法。虽然本研究集中在EAs上，但我们的方法的可扩展性为将llm应用于其他传统算法开辟了途径，如粒子群优化（PSO）、蚁群优化（ACO）和最近的质量-多样性（QD）优化算法。我们的发现旨在激发未来在llm和传统算法的交叉点上的研究，鼓励创新的应用。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>HQA-Attack_ Toward High Quality Black-Box Hard-Label Adversarial Attack on Text</title>
      <link href="/2024/04/21/hqa-attack-toward-high-quality-black-box-hard-label-adversarial-attack-on-text/"/>
      <url>/2024/04/21/hqa-attack-toward-high-quality-black-box-hard-label-adversarial-attack-on-text/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><strong>Summary:</strong><br />Black-box hard-label adversarial attack on text is a practical and challenging task, as the text data space is inherently discrete and non-differentiable, and only the predicted label is accessible. Research on this problem is still in the embryonic stage and only a few methods are available. Nevertheless, existing methods rely on the complex heuristic algorithm or unreliable gradient estimation strategy, which probably fall into the local optimum and inevitably consume numerous queries, thus are difficult to craft satisfactory adversarial examples with high semantic similarity and low perturbation rate in a limited query budget. To alleviate above issues, we propose a simple yet effective framework to generate high quality textual adversarial examples under the black-box hard-label attack scenarios, named HQA-Attack. Specifically, after initializing an adversarial example randomly, HQA-attack first constantly substitutes original words back as many as possible, thus shrinking the perturbation rate. Then it leverages the synonym set of the remaining changed words to further optimize the adversarial example with the direction which can improve the semantic similarity and satisfy the adversarial condition simultaneously. In addition, during the optimizing procedure, it searches a transition synonym word for each changed word, thus avoiding traversing the whole synonym set and reducing the query number to some extent. Extensive experimental results on five text classification datasets, three natural language inference datasets and two real-world APIs have shown that the proposed HQA-Attack method outperforms other strong baselines significantly.</p><p><strong>Background：</strong><br />      深度神经网络（DNN）已经取得了巨大的成功，并且在以下领域非常受欢迎：各个领域，例如计算机视觉，自然语言处理，机器人技术等等。 尽管 DNN 模型取得了令人鼓舞的性能，但仍存在一些问题对其鲁棒性的担忧，因为有证据表明，即使是对输入的轻微扰动数据可以欺骗这些模型，使其产生错误的预测，这些令人不安的示例被命名为对抗性示例。 调查对抗性背后的生成原理例子似乎是提高神经网络鲁棒性的一种有前途的方法，这激励了关于对抗性攻击的研究。 大多数现有的对抗性攻击方法都集中在计算机上愿景并已得到充分探索。 然而，对文本数据的对抗性攻击是仍然具有挑战性，因为不仅文本数据空间本质上是离散且不可微的，而且另外稍微改变一下单词也可能会影响语法的流畅性和语义的一致性严重地。<br />基于受害者模型的可访问性级别，现有的文本对抗攻击方法可以被归类为白盒攻击和黑盒攻击。 对于白盒攻击时，假设攻击者拥有有关受害者模型的完整信息，包括训练数据、模型架构和参数。 因此，很容易将这种类型的攻击表述为优化问题并利用梯度信息生成对抗性示例。 然而，由于大多数模型开发者不可能公开所有的模型和数据信息，白盒攻击似乎过于理想化，在现实应用中无法很好地发挥作用。 对于黑匣子攻击时，假设攻击者只能访问预测结果，例如置信度分数或预测标签，这看起来更现实。 现有的黑盒文本攻击方法可以分为软标签设置和硬标签设置。 对于软标签方法，他们要求受害者模型提供置信度分数来计算每个问题的重要性单词，然后依次替换单词，直到生成对抗性示例。 然而，它是也不切实际，因为大多数真实的 API 不允许用访问置信度分数。 对于硬标签方法，他们只需要知道受害者模型的预测标签即可完成攻击任务，因而更具有实用性和前景。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713077959296-34022000-1cc1-4b5e-94bd-3432d3ab406b.png#averageHue=%23f6f1ea&clientId=u3dc7df86-cfe5-4&from=paste&height=356&id=u1a151193&originHeight=356&originWidth=369&originalType=binary&ratio=1&rotation=0&showTitle=false&size=64855&status=done&style=none&taskId=uf43032d3-8e96-49d1-8d18-3b8d238cfe2&title=&width=369" alt="1713077949376.png"><br />仅提出了少数几种方法处理黑盒硬标签文本广告对抗攻击任务，主要依靠基于启发式的或基于梯度的策略。 具体来说，HLGA是第一种硬标签对抗攻击方法，利用基于群体的启发式优化算法来制作合理且语义相似的对抗性示例。 然而，作为需要大量的对抗性可预测群体，基于群体的优化策略很容易陷入局部最优，HLGA不可避免地会消耗大量的查询次数。TextHoaxer将文本数据上的预算硬标签对抗性攻击任务制定为连续词嵌入中扰动矩阵的梯度优化问题空间。 LeapAttack通过设计一种可以互换离散替换和连续向量的新颖机制来利用基于梯度的优化。 虽然这些基于梯度的方法在一定程度上提高了查询效率，但仍然需要一些不必要的查询梯度估计不准确造成的。 此外，在预算紧张的场景下，查询效率低下会直接对语义相似度和扰动率带来严重的副作用。</p><p><strong>Contributions：</strong><br />为了缓解上述问题，我们提出了一个简单而有效的框架来产生高高质量黑盒硬标签对抗攻击，称为 HQA-Attack。 HQAAttack的概述如图1所示。“高质量”是指HQA-Attack方法可以生成在严格查询下具有高语义相似性和低扰动率的对抗性示例预算。 具体来说，HQA-Attck首先通过初始化生成对抗样本，然后依次将尽可能多的原始单词替换回去，从而缩小扰动率。最后，它利用同义词集进一步优化对抗性示例，方向为可以提高语义相似度并同时满足对抗条件。 此外，为了避免遍历同义词集，它会为每个更改的单词找到一个过渡同义词，从而在一定程度上减少了查询次数。 八个公共基准的实验结果数据集和两个真实的API（谷歌云和阿里云）证明HQA Attack在语义相似度和扰动率方面比其他强基线表现更好在相同的查询预算下。</p><p><strong>Method：</strong><br />软标签设置中的对抗性攻击依赖于所有类别的概率分布生成对抗性例子。 一系列策略利用贪心算法制作对抗性示例，首先确定单词替换顺序并贪婪地替换在此顺序下的每个单词。 TextFooler首先根据删除每个单词后的预测变化，然后根据单词重要性，直到生成对抗性示例。 类似地，TextBugger计算通过比较预测分别得出句子的重要性和单词的重要性移除它们之前和之后。 此外，还有一些方法使用组合生成对抗性示例的优化算法。<br />硬标签设置中的对抗性攻击只允许访问预测的标签，这看起来更具有挑战性和实用性。 HLGA是第一个硬标签文本对抗攻击方法。 它用随机初始化和搜索空间缩减以获得初期的对抗性示例，然后使用遗传算法包括变异、选择和交叉三种操作进一步优化对抗性的例子。 虽然 HLGA 可以生成具有高语义的对抗性示例与原始示例相似且扰动率低，需要维持较大的候选每次迭代都会设置，这会浪费大量的查询。 为了缓解这个问题，TextHoaxer使用词嵌入空间来表示文本，并引入扰动矩阵和新颖的目标函数由语义相似项、成对扰动约束组成和稀疏约束。 通过使用基于梯度的策略来优化扰动矩阵，TextHoaxer 可以在紧张的预算内生成适当的对抗性示例。 LeapAttack 是另一种基于梯度的方法。 随机初始化后，它通过以下方式优化对抗性示例不断地将示例移近决策边界，估计梯度并找到更新对抗性例子的正确词语。 在附录 K 中，我们进一步讨论了一些潜在的硬标签文本对抗攻击的应用场景。<br />在本文中，我们关注黑盒硬标签文本对抗攻击，即攻击者只能从受害者模型中获取预测的标签来生成对抗的例子。具体来说，给出了一个原始的例子<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713082784676-4ef96ee8-1fe1-406a-91df-432e3cb307ca.png#averageHue=%23f9f6f3&clientId=u718981f7-f8e3-4&from=paste&height=24&id=uce0e5c0b&originHeight=24&originWidth=152&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1939&status=done&style=none&taskId=ud5ac983b-6e88-4532-89c1-6683b59d733&title=&width=152" alt="image.png">有地面真实标签<img src="https://cdn.nlark.com/yuque/__latex/bf98c0ddcbe9c1e535f767c78c3aa813.svg#card=math&code=y&id=UKSH5">，其中<img src="https://cdn.nlark.com/yuque/__latex/d99fd2df7b5f652a4b7fc593fb9df750.svg#card=math&code=w_i&id=ukk5k">是第<img src="https://cdn.nlark.com/yuque/__latex/2443fbcfeb7e85e1d62b6f5e4f27207e.svg#card=math&code=i&id=i9fX0">个单词，<img src="https://cdn.nlark.com/yuque/__latex/df378375e7693bdcf9535661c023c02e.svg#card=math&code=n&id=bE0ml">是<img src="https://cdn.nlark.com/yuque/__latex/712ecf7894348e92d8779c3ee87eeeb0.svg#card=math&code=x&id=Ioh45">中的单词总数。本任务旨在建立一个敌对的例子<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713083011247-8c783361-4561-4e96-b2b8-86b8668fec1f.png#averageHue=%23f9f6f2&clientId=u718981f7-f8e3-4&from=paste&height=23&id=u27c6b4e4&originHeight=23&originWidth=170&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1987&status=done&style=none&taskId=ud85e2b1f-1a08-48c9-b633-1aba79a5cda&title=&width=170" alt="image.png">。通过将包含<img src="https://cdn.nlark.com/yuque/__latex/d99fd2df7b5f652a4b7fc593fb9df750.svg#card=math&code=w_i&id=vF61T">本身的同义词集<img src="https://cdn.nlark.com/yuque/__latex/f68a44577aeba338f812a2315c0c5302.svg#card=math&code=S%28w_i%29&id=WBxqG">中的同义词<img src="https://cdn.nlark.com/yuque/__latex/8c114c023858474e0051b31ac447af72.svg#card=math&code=w%27_i&id=lPQcm">替换为原始词<img src="https://cdn.nlark.com/yuque/__latex/d99fd2df7b5f652a4b7fc593fb9df750.svg#card=math&code=w_i&id=bYx5e">，从而误导受害者模型<img src="https://cdn.nlark.com/yuque/__latex/18f3c2855f0e85a1ac2257f64d917144.svg#card=math&code=f&id=QM0bb">输出一个不正确的预测结果：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713083207480-30cd11e0-1729-4933-a5dc-07527796720b.png#averageHue=%23faf7f4&clientId=u718981f7-f8e3-4&from=paste&height=29&id=ua217848e&originHeight=29&originWidth=147&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2314&status=done&style=none&taskId=ue8cd070c-cf4b-4237-beb3-15882afeb1d&title=&width=147" alt="image.png"><br />其中，等式(1)可以看作是对抗性的情况。可能存在几个对抗性的例子可以满足等式(1)，但最优的对抗性例子x˚是在所有候选样本中与原始例子x语义相似性最高的例子。正式地，<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713083228482-3b5d4af7-78b9-4f00-baf5-e3e491e525fe.png#averageHue=%23fcfaf7&clientId=u718981f7-f8e3-4&from=paste&height=41&id=u92645bbf&originHeight=41&originWidth=355&originalType=binary&ratio=1&rotation=0&showTitle=false&size=5336&status=done&style=none&taskId=u394f268a-0681-4074-9665-4a6f4cc47a2&title=&width=355" alt="image.png"><br />其中，<img src="https://cdn.nlark.com/yuque/__latex/d70bff217a1d9c948dd4301cf9ba2637.svg#card=math&code=Sim%28x%2C%20x%27%29&id=r95wr">是<img src="https://cdn.nlark.com/yuque/__latex/712ecf7894348e92d8779c3ee87eeeb0.svg#card=math&code=x&id=dUjuU">和<img src="https://cdn.nlark.com/yuque/__latex/a9cc33aa0d01f5a6ed94d209c0278ac3.svg#card=math&code=x%27&id=w8KFr">之间的语义相似性。表1详细总结了符号说明。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713083351935-fbc5b44f-ce48-495b-87ad-71f11b19b987.png#averageHue=%23f6f3f0&clientId=u718981f7-f8e3-4&from=paste&height=269&id=ud4e945e1&originHeight=269&originWidth=472&originalType=binary&ratio=1&rotation=0&showTitle=false&size=48617&status=done&style=none&taskId=u9f00e199-6f70-4f2d-a98e-ad022cc0d7e&title=&width=472" alt="image.png"><br />为了完成黑盒硬标签文本对抗攻击任务，我们遵循以前的工作首先利用随机初始化来生成对抗性示例。 具体来说，考虑原始示例中词性 (POS) 为名词、动词、副词和形容词的每个单词 <img src="https://cdn.nlark.com/yuque/__latex/d99fd2df7b5f652a4b7fc593fb9df750.svg#card=math&code=w_i&id=xGyLE">，我们随机选择一个同义词<img src="https://cdn.nlark.com/yuque/__latex/8c114c023858474e0051b31ac447af72.svg#card=math&code=w%27_i&id=qdiTd">来自 <img src="https://cdn.nlark.com/yuque/__latex/d99fd2df7b5f652a4b7fc593fb9df750.svg#card=math&code=w_i&id=PLe9J"> 的同义词集 <img src="https://cdn.nlark.com/yuque/__latex/f68a44577aeba338f812a2315c0c5302.svg#card=math&code=S%28w_i%29&id=PucNY"> 作为 <img src="https://cdn.nlark.com/yuque/__latex/d99fd2df7b5f652a4b7fc593fb9df750.svg#card=math&code=w_i&id=k31XQ">的替换，和重复此过程，直到生成对抗性示例 <img src="https://cdn.nlark.com/yuque/__latex/a9cc33aa0d01f5a6ed94d209c0278ac3.svg#card=math&code=x%27&id=mMpxz">满足对抗条件。显然，使用随机初始化来生成对抗样本通常需要改变原始示例中存在多个单词，因此必然导致语义相似度较低扰动率大。 为了缓解上述问题，我们尝试在第<img src="https://cdn.nlark.com/yuque/__latex/cead1760d9d5723460c4b8d4028f113a.svg#card=math&code=t&id=j9N4R">次迭代<img src="https://cdn.nlark.com/yuque/__latex/e8f9a7eed256da672986d0d8237ce9d5.svg#card=math&code=x%27_t&id=Hkwx7">中迭代优化原始例<img src="https://cdn.nlark.com/yuque/__latex/712ecf7894348e92d8779c3ee87eeeb0.svg#card=math&code=x&id=DfBD8">和对抗性例之间的语义相似性，其中<img src="https://cdn.nlark.com/yuque/__latex/8f04bdf7645e34197a84fb043aaf0198.svg#card=math&code=1%5Cle%20t%20%5Cle%20T&id=BsCfI">和<img src="https://cdn.nlark.com/yuque/__latex/1553dae3cc5c15cddb4f5b5a367b0aba.svg#card=math&code=T&id=QKFST">为迭代总数。<br />为了提高生成的对抗样本的语义相似度，之前的工作首先以每个原词带来的语义相似度提升作为衡量标准决定替换顺序，然后在每次迭代中不断放回原来的单词。 它意味着在每次迭代中，通过遍历对抗性示例中的每个单词，语义相似度改进只计算一次，并且替换顺序是预先确定的。然而，用原始单词进行每次替换都会改变生成的中间结果对抗性示例，从而影响原始示例和示例之间的语义相似度中间生成对抗性示例，因此只需计算语义相似度改进在每次迭代开始时确定替换顺序不准确。<br />针对上述问题，我们建议不断地替换原词，这样可以使中间生成的对抗样本与原始示例，直到违反对抗条件。具体来说，给定第t次迭代中的原始样本<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713082784676-4ef96ee8-1fe1-406a-91df-432e3cb307ca.png#averageHue=%23f9f6f3&clientId=u718981f7-f8e3-4&from=paste&height=24&id=PmmvO&originHeight=24&originWidth=152&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1939&status=done&style=none&taskId=ud5ac983b-6e88-4532-89c1-6683b59d733&title=&width=152" alt="image.png">和对抗性例子<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713083011247-8c783361-4561-4e96-b2b8-86b8668fec1f.png#averageHue=%23f9f6f2&clientId=u718981f7-f8e3-4&from=paste&height=23&id=dBV1u&originHeight=23&originWidth=170&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1987&status=done&style=none&taskId=ud85e2b1f-1a08-48c9-b633-1aba79a5cda&title=&width=170" alt="image.png">，我们可以用以下步骤替换原始单词。<br />1.从<img src="https://cdn.nlark.com/yuque/__latex/712ecf7894348e92d8779c3ee87eeeb0.svg#card=math&code=x&id=oklYO">中挑选出一个合适的替换词<img src="https://cdn.nlark.com/yuque/__latex/6d65ccc7176953587d009efc17010568.svg#card=math&code=w_%2A&id=xFkgP">，公式如下：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713084238064-7b6ab33f-f991-4aa6-a00e-7f3df9d46dad.png#averageHue=%23fbf8f4&clientId=u718981f7-f8e3-4&from=paste&height=34&id=u61df3641&originHeight=34&originWidth=362&originalType=binary&ratio=1&rotation=0&showTitle=false&size=6175&status=done&style=none&taskId=u32cf9d82-8aaf-431f-a2fb-c482f19ef94&title=&width=362" alt="image.png"><br />其中，<img src="https://cdn.nlark.com/yuque/__latex/85fac01fbc81484467b1ec4fe2dcba22.svg#card=math&code=Sim%28x%2Cx%27_t%28w_i%29%29&id=zikY8">是<img src="https://cdn.nlark.com/yuque/__latex/712ecf7894348e92d8779c3ee87eeeb0.svg#card=math&code=x&id=cJU1I">和<img src="https://cdn.nlark.com/yuque/__latex/0c2a385221c9e9e36617711539f82727.svg#card=math&code=x%27_t%28w_i%29&id=NpzQM">之间的语义相似度，<img src="https://cdn.nlark.com/yuque/__latex/0c2a385221c9e9e36617711539f82727.svg#card=math&code=x%27_t%28w_i%29&id=Stcf9">是用<img src="https://cdn.nlark.com/yuque/__latex/d99fd2df7b5f652a4b7fc593fb9df750.svg#card=math&code=w_i&id=ie0jq">替换对应的单词<img src="https://cdn.nlark.com/yuque/__latex/8c114c023858474e0051b31ac447af72.svg#card=math&code=w%27_i&id=pYjxI">得到的例子。<img src="https://cdn.nlark.com/yuque/__latex/5246d05f45726eeea81453b5f3c6b19c.svg#card=math&code=C%28f%2Cx%2Cx%27_t%28w_i%29%29&id=GWWAY">是一个二值函数，定义为：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713084600125-f4de43da-7188-4c75-b679-7ac8905fc1fd.png#averageHue=%23fbf8f5&clientId=u718981f7-f8e3-4&from=paste&height=48&id=u86215462&originHeight=48&originWidth=333&originalType=binary&ratio=1&rotation=0&showTitle=false&size=5998&status=done&style=none&taskId=ue4ba01ba-6769-4fcc-91f6-f85e5eec75b&title=&width=333" alt="image.png"><br />其中，<img src="https://cdn.nlark.com/yuque/__latex/18f3c2855f0e85a1ac2257f64d917144.svg#card=math&code=f&id=BwbZw">为受害者模型。如果<img src="https://cdn.nlark.com/yuque/__latex/2c35e0fa4a53bb79e2c88163f89000ca.svg#card=math&code=f%28x%29%20%5Cneq%20f%28x%27_t%28w_i%29%29&id=JPy91">，则<img src="https://cdn.nlark.com/yuque/__latex/a42a4fc28b384cc408de066beed57485.svg#card=math&code=C&id=kvIpe">等于1，否则为0。<br />2.如果<img src="https://cdn.nlark.com/yuque/__latex/27b34dee715897c715cd461bc2642afc.svg#card=math&code=C%28f%2Cx%2Cx%27_t%28w_%2A%29%29%20%3D%201&id=eSuSk">，则表示<img src="https://cdn.nlark.com/yuque/__latex/e7b9a4c85936635c359399ef7fe7436d.svg#card=math&code=x%27_t%28w_%2A%29&id=BrBZR">可以成功攻击。我们用<img src="https://cdn.nlark.com/yuque/__latex/e8f9a7eed256da672986d0d8237ce9d5.svg#card=math&code=x%27_t&id=kb0iw">中对应的原始单词替换为<img src="https://cdn.nlark.com/yuque/__latex/6d65ccc7176953587d009efc17010568.svg#card=math&code=w_%2A&id=hDVAZ">，并重复上述步骤。<br />3.如果<img src="https://cdn.nlark.com/yuque/__latex/05b4ce6ecc0c57dbd686c9d849f9f6ae.svg#card=math&code=C%28f%2Cx%2Cx%27_t%28w_%2A%29%29%20%3D%200&id=iBSRV">，则表示<img src="https://cdn.nlark.com/yuque/__latex/e7b9a4c85936635c359399ef7fe7436d.svg#card=math&code=x%27_t%28w_%2A%29&id=IYyGY">不能满足对抗性条件。我们终止交换过程，并返回上一步的结果。<br />经过上述过程，我们可以得到一个新的对抗样本<img src="https://cdn.nlark.com/yuque/__latex/e8f9a7eed256da672986d0d8237ce9d5.svg#card=math&code=x%27_t&id=c7a4I">可以保留原来的尽可能多的单词，从而提高语义相似度并降低扰动率。算法流程如附录A所示，计算复杂度和分析查询编号见附录C.1。<br />为了进一步提高生成的对抗样本的质量，我们优化了对抗样本例如，利用每个单词的同义词集。 有人可能会说我们可以直接遍历同义词集合寻找语义相似度最高的最理想同义词词并同时满足对抗条件。 然而，在大多数实际应用中场景下，查询数量通常是有限的。 为了避免遍历同义词集，我们建议通过以下两个步骤优化对抗性示例。 (1) 确定优化方案命令; (2)依次更新对抗样本。 计算复杂度分析查询编号见附录C.2。<br />在这一步中，我们的目标是确定一个合适的优化顺序。为了保证生成的对抗性实例的多样性，我们利用抽样方法来确定优化顺序。抽样方法所使用的概率分布如下。对于<img src="https://cdn.nlark.com/yuque/__latex/e8f9a7eed256da672986d0d8237ce9d5.svg#card=math&code=x%27_t&id=ITDyc">中的<img src="https://cdn.nlark.com/yuque/__latex/8c114c023858474e0051b31ac447af72.svg#card=math&code=w%27_i&id=fodY0">和<img src="https://cdn.nlark.com/yuque/__latex/712ecf7894348e92d8779c3ee87eeeb0.svg#card=math&code=x&id=XWdR0">中的<img src="https://cdn.nlark.com/yuque/__latex/d99fd2df7b5f652a4b7fc593fb9df750.svg#card=math&code=w_i&id=oOC9A">，我们首先使用反拟合的词向量[29]得到它们对应的词向量，并计算它们之间的余弦距离如下：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713085196906-fdd152fa-09b5-44cb-975d-9441dbc7b921.png#averageHue=%23faf8f4&clientId=u718981f7-f8e3-4&from=paste&height=29&id=u4a69ace2&originHeight=29&originWidth=183&originalType=binary&ratio=1&rotation=0&showTitle=false&size=3178&status=done&style=none&taskId=uc00696ff-c57b-4fb6-98ee-2bb68edd29c&title=&width=183" alt="image.png"><br />其中，<img src="https://cdn.nlark.com/yuque/__latex/2ad38a23b40c4d62ec987290b8c64cac.svg#card=math&code=v_%7Bw_i%7D&id=yRdbo">和<img src="https://cdn.nlark.com/yuque/__latex/1952fef64bee3dba944df5f93f5ae3e9.svg#card=math&code=v_%7Bw%27_i%7D&id=Floqq">分别表示<img src="https://cdn.nlark.com/yuque/__latex/d99fd2df7b5f652a4b7fc593fb9df750.svg#card=math&code=w_i&id=V4pIE">和<img src="https://cdn.nlark.com/yuque/__latex/8c114c023858474e0051b31ac447af72.svg#card=math&code=w%27_i&id=PXchi">的单词向量。<img src="https://cdn.nlark.com/yuque/__latex/dc4ff2f7f8c631e916f353e0efda1225.svg#card=math&code=cos%28.%2C.%29&id=enxQR">是余弦相似度函数。然后我们用以下公式计算与<img src="https://cdn.nlark.com/yuque/__latex/d99fd2df7b5f652a4b7fc593fb9df750.svg#card=math&code=w_i&id=zijPK">在<img src="https://cdn.nlark.com/yuque/__latex/712ecf7894348e92d8779c3ee87eeeb0.svg#card=math&code=x&id=PGUfS">中的位置相关的概率<img src="https://cdn.nlark.com/yuque/__latex/39c69fbad0041c1d5caa9acf313cb0e6.svg#card=math&code=p_i&id=aQoQX">：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713085375643-e286e7a4-0781-4935-96ee-6c55b2e707fa.png#averageHue=%23f6f4f3&clientId=u718981f7-f8e3-4&from=paste&height=50&id=ud57bceef&originHeight=50&originWidth=170&originalType=binary&ratio=1&rotation=0&showTitle=false&size=3781&status=done&style=none&taskId=ub40b86d5-ada4-4ab5-bbaf-e52245cd490&title=&width=170" alt="image.png"><br />其中，<img src="https://cdn.nlark.com/yuque/__latex/4760e2f007e23d820825ba241c47ce3b.svg#card=math&code=m&id=UoRW8">是在<img src="https://cdn.nlark.com/yuque/__latex/e8f9a7eed256da672986d0d8237ce9d5.svg#card=math&code=x%27_t&id=DnSZy">和<img src="https://cdn.nlark.com/yuque/__latex/712ecf7894348e92d8779c3ee87eeeb0.svg#card=math&code=x&id=ouwhQ">之间改变的单词的总数。根据概率分布，我们可以得到<img src="https://cdn.nlark.com/yuque/__latex/23ba71a1373c0f73e4f52920cc774716.svg#card=math&code=x%27t&id=MCqm8">的优化顺序。<br />根据优化顺序，我们用同义词集按顺序更新对抗性示例。特别是，对于第t次迭代中的对抗性示例<img src="https://cdn.nlark.com/yuque/__latex/e8f9a7eed256da672986d0d8237ce9d5.svg#card=math&code=x%27_t&id=yM0DT">，我们用以下步骤来更新它。(1)查找过渡词；(2)估计更新方向；(3)更新对抗性示例。<br />**找到过渡词:**这一步的目的是搜索一个合理的过渡词，从而避免遍历每个更改的单词的同义词集。给定敌对的例子<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713083011247-8c783361-4561-4e96-b2b8-86b8668fec1f.png#averageHue=%23f9f6f2&clientId=u718981f7-f8e3-4&from=paste&height=23&id=Jrbdq&originHeight=23&originWidth=170&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1987&status=done&style=none&taskId=ud85e2b1f-1a08-48c9-b633-1aba79a5cda&title=&width=170" alt="image.png">和当前优化单<img src="https://cdn.nlark.com/yuque/__latex/8c114c023858474e0051b31ac447af72.svg#card=math&code=w%27_i&id=wV68y">，我们随机选择<img src="https://cdn.nlark.com/yuque/__latex/72cb3a229067770aeb6caa625a65a1a1.svg#card=math&code=r&id=ijaLN">同义词构造设置<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713085627422-378b7547-145c-4f0e-bb8e-89e782c30fd4.png#averageHue=%23faf6f2&clientId=u718981f7-f8e3-4&from=paste&height=29&id=u521286dd&originHeight=29&originWidth=189&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2972&status=done&style=none&taskId=u682a5131-2a5c-4add-97a2-ece2738ea5f&title=&width=189" alt="image.png">，使用每个元素替换<img src="https://cdn.nlark.com/yuque/__latex/79b733ad92335d362b8400a54193e034.svg#card=math&code=w%27_i%0A&id=AclK3">和<img src="https://cdn.nlark.com/yuque/__latex/ae4caee5e098d917646e8f24d8d4d1be.svg#card=math&code=x%27_i&id=uZ0ac">，然后获得过渡词<img src="https://cdn.nlark.com/yuque/__latex/6ad45305e4fbc50c78ef559008e90987.svg#card=math&code=%5Coverline%20w_i&id=Ba8kQ">与以下公式：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713085742668-df5508cb-c2ea-4df3-b8f6-04993240adb8.png#averageHue=%23fcfaf7&clientId=u718981f7-f8e3-4&from=paste&height=47&id=ue20362e7&originHeight=47&originWidth=391&originalType=binary&ratio=1&rotation=0&showTitle=false&size=7288&status=done&style=none&taskId=ued3cb446-c34f-46a2-8d17-86a4ae32303&title=&width=391" alt="image.png"><br />其中<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713085871195-cd9861ef-613f-4dd6-abc0-ffb9f01effcb.png#averageHue=%23fcf9f5&clientId=u718981f7-f8e3-4&from=paste&height=38&id=u5d038b85&originHeight=38&originWidth=66&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2145&status=done&style=none&taskId=ueb664c0a-9a32-4a68-a017-c0e4483be21&title=&width=66" alt="image.png">是用<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713085888921-1108d2bc-8a83-43ab-a7cd-8fee685624b8.png#averageHue=%23faf7f3&clientId=u718981f7-f8e3-4&from=paste&height=29&id=uf859f71b&originHeight=29&originWidth=74&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1891&status=done&style=none&taskId=udbde87d0-0898-480a-bf0f-028705df4d5&title=&width=74" alt="image.png">替换<img src="https://cdn.nlark.com/yuque/__latex/e8f9a7eed256da672986d0d8237ce9d5.svg#card=math&code=x%27_t&id=FESIW">中相应的单词<img src="https://cdn.nlark.com/yuque/__latex/8c114c023858474e0051b31ac447af72.svg#card=math&code=w%27_i&id=MCz2F">得到的例子。根据等式(7)，我们可以得到，<img src="https://cdn.nlark.com/yuque/__latex/6ad45305e4fbc50c78ef559008e90987.svg#card=math&code=%5Coverline%20w_i&id=yACfh">可以使示例具有对抗性，并在一定程度上提高语义相似性，同时避免通过同义词集。此外，我们还可以在过渡词<img src="https://cdn.nlark.com/yuque/__latex/6ad45305e4fbc50c78ef559008e90987.svg#card=math&code=%5Coverline%20w_i&id=ngt8P">周围搜索其他可能的替换词。<br /><strong>估计更新的方向：</strong>由于过渡词<img src="https://cdn.nlark.com/yuque/__latex/6ad45305e4fbc50c78ef559008e90987.svg#card=math&code=%5Coverline%20w_i&id=Mp1B2">来源于一个随机生成的同义词集，我们可以以一个合理的方向进一步优化它。具体来说，我们首先通过从<img src="https://cdn.nlark.com/yuque/__latex/8be6885fe1c17117a386d48ae4444ef6.svg#card=math&code=S%28%5Coverline%20w_i%29&id=OtcMG">中随机抽样<img src="https://cdn.nlark.com/yuque/__latex/df976ff7fcf17d60490267d18a1e3996.svg#card=math&code=k&id=IU5l0">个同义词来生成集合<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086035746-4c1a15b2-c07c-4399-b2d3-89ed1bf98edb.png#averageHue=%23f8f4f0&clientId=u718981f7-f8e3-4&from=paste&height=27&id=ufafb7796&originHeight=27&originWidth=189&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2957&status=done&style=none&taskId=u5e653393-bfcf-44e2-8457-8d3af4b9e2a&title=&width=189" alt="image.png">，然后获得设置<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086144939-67e84e73-c6e5-4c16-ad8e-27506b338e2e.png#averageHue=%23f9f5ef&clientId=u718981f7-f8e3-4&from=paste&height=26&id=uf630f614&originHeight=26&originWidth=286&originalType=binary&ratio=1&rotation=0&showTitle=false&size=4079&status=done&style=none&taskId=ubcb0aefb-4341-4425-ae7d-58982479dbe&title=&width=286" alt="image.png">，其中<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086185942-c015462f-e565-452f-ad80-5ca329893684.png#averageHue=%23faf6f0&clientId=u718981f7-f8e3-4&from=paste&height=30&id=ua15148b3&originHeight=30&originWidth=65&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2115&status=done&style=none&taskId=u24c35c68-b0ca-4972-9f9f-4ee15a95e39&title=&width=65" alt="image.png">是用<img src="https://cdn.nlark.com/yuque/__latex/8c114c023858474e0051b31ac447af72.svg#card=math&code=w%27_i&id=pUbbE">替换<img src="https://cdn.nlark.com/yuque/__latex/ae4caee5e098d917646e8f24d8d4d1be.svg#card=math&code=x%27_i&id=I7eck">z中的<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086271313-7a939e4f-1147-4e3c-b4ef-b2b1712e8e27.png#averageHue=%23e1c095&clientId=u718981f7-f8e3-4&from=paste&height=26&id=ue6a361b8&originHeight=26&originWidth=29&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1082&status=done&style=none&taskId=uc29fe2bf-dd39-4d54-88a8-8e4ddea45cf&title=&width=29" alt="image.png">例子。通过计算每个元素之间的语义相似度O和原始文本x，我们可以得到集<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086287872-ef50dad4-2f1a-4f4e-b3fd-51036466a55f.png#averageHue=%23f9f6f2&clientId=u718981f7-f8e3-4&from=paste&height=25&id=u22fdf0e1&originHeight=25&originWidth=179&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2609&status=done&style=none&taskId=u5cc9d886-ad1a-4bc4-9ce9-95d64467e34&title=&width=179" alt="image.png">，其中<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086302311-a0f632ba-06cf-40b9-8a96-013687c5f4da.png#averageHue=%23f9f5f0&clientId=u718981f7-f8e3-4&from=paste&height=26&id=u8c683dea&originHeight=26&originWidth=185&originalType=binary&ratio=1&rotation=0&showTitle=false&size=3981&status=done&style=none&taskId=ua311e183-119f-4654-97cc-148669ad727&title=&width=185" alt="image.png">是x和<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086317625-ffb855e0-47c4-4ded-b2b8-916907d0f1f7.png#averageHue=%23f9f5ee&clientId=u718981f7-f8e3-4&from=paste&height=28&id=u4f3cc588&originHeight=28&originWidth=63&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2139&status=done&style=none&taskId=u80cd43e8-618f-4b0f-8a1e-66390ed4adf&title=&width=63" alt="image.png">之间的语义相似性。以类似的方式，x和<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086327459-63f988b7-2cdd-49c0-89d0-d71bbc140a12.png#averageHue=%23f9f5ee&clientId=u718981f7-f8e3-4&from=paste&height=28&id=uab5415c2&originHeight=28&originWidth=63&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2139&status=done&style=none&taskId=uad83d0fe-230b-40af-a1e8-4886c602099&title=&width=63" alt="image.png">旋转之间的语义相似度可以通过<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086346941-afdb7bd4-a383-4dc7-bfae-fbe969bb61fc.png#averageHue=%23f7f2ed&clientId=u718981f7-f8e3-4&from=paste&height=22&id=udeb2babd&originHeight=22&originWidth=161&originalType=binary&ratio=1&rotation=0&showTitle=false&size=3125&status=done&style=none&taskId=u919b5c9a-e16e-41e2-80fa-88889c076d6&title=&width=161" alt="image.png">来计算。<br />直观地说，如果<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086444411-685aedc9-1e2b-4a4e-87b4-0de65b75339f.png#averageHue=%23faf8f5&clientId=u718981f7-f8e3-4&from=paste&height=26&id=ue692038e&originHeight=26&originWidth=101&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1695&status=done&style=none&taskId=ua0f22fc2-0ef7-4f99-8f02-704cfff5737&title=&width=101" alt="image.png">，则表示将单词向量<img src="https://cdn.nlark.com/yuque/__latex/89111f3d3fc401be99edcd8a8211022c.svg#card=math&code=v_%7B%5Coverline%20w_i%7D&id=ZNr8e">推向会增加语义相似度，即<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086499432-aab6e032-3721-4f44-b1aa-cc9f86712d88.png#averageHue=%23f9f5f2&clientId=u718981f7-f8e3-4&from=paste&height=24&id=u0e949a14&originHeight=24&originWidth=93&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1390&status=done&style=none&taskId=u6d8791bc-0849-490d-8a13-0dd07ff44e2&title=&width=93" alt="image.png">是可以提高语义相似度的方向。如果<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086511617-fa697ee8-fa7d-413d-8b55-6b06abefb44d.png#averageHue=%23f9f6f3&clientId=u718981f7-f8e3-4&from=paste&height=23&id=u1c2923a7&originHeight=23&originWidth=99&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1668&status=done&style=none&taskId=uda03d6ab-58df-4daf-8b90-2f6c1fffec2&title=&width=99" alt="image.png">，沿单词向量<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086539711-b172419b-2560-4870-98e1-75c4ccb9b924.png#averageHue=%23f9f6f2&clientId=u718981f7-f8e3-4&from=paste&height=25&id=u6640b418&originHeight=25&originWidth=89&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1379&status=done&style=none&taskId=u55beaf7b-4477-4a83-a1cc-127ae650051&title=&width=89" alt="image.png">的逆方向移动单词向量可以提高语义相似性。基于上述直觉，我们通过对k个可能方向的加权平均来估计最终的更新方向u。正式地，<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086555522-0fb36885-c2e2-4fc2-ad07-9d825d731c77.png#averageHue=%23faf9f7&clientId=u718981f7-f8e3-4&from=paste&height=58&id=u0338dd03&originHeight=58&originWidth=196&originalType=binary&ratio=1&rotation=0&showTitle=false&size=4188&status=done&style=none&taskId=ud60cd329-264e-42df-bcc4-53585389e16&title=&width=196" alt="image.png"><br />其中<img src="https://cdn.nlark.com/yuque/__latex/acdcbdeb2eccdf3e6705b176a0b9730d.svg#card=math&code=%5Calpha%20_j&id=IBbTB">是与方向<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086653403-40d86847-545d-4b06-9e95-21912238b5ab.png#averageHue=%23f9f6f2&clientId=u718981f7-f8e3-4&from=paste&height=24&id=u43b07e2d&originHeight=24&originWidth=95&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1524&status=done&style=none&taskId=u0f1b07f9-9587-4598-9bbc-6cd027fe44a&title=&width=95" alt="image.png">相关的对应权重，它可以用<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086664492-769c68ab-daea-4d98-8dda-44d212a24603.png#averageHue=%23f9f7f4&clientId=u718981f7-f8e3-4&from=paste&height=32&id=u507386b9&originHeight=32&originWidth=248&originalType=binary&ratio=1&rotation=0&showTitle=false&size=3839&status=done&style=none&taskId=u6d161348-aa66-4c9e-b474-0f15ebccb05&title=&width=248" alt="image.png">来计算。<br /><strong>更新对抗性的示例：</strong>由于文本数据的离散性质，我们需要使用更新方向u从<img src="https://cdn.nlark.com/yuque/__latex/986f2182bf3b8e740e95a01577f3617d.svg#card=math&code=S%EF%BC%88w_i%EF%BC%89&id=NZMwq">挑选出相应的替换词<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086818343-8eb2e510-2ce1-4c17-8e92-54cf87eec062.png#averageHue=%23d9ba95&clientId=u718981f7-f8e3-4&from=paste&height=20&id=u63a0beed&originHeight=20&originWidth=22&originalType=binary&ratio=1&rotation=0&showTitle=false&size=736&status=done&style=none&taskId=ufdc32f86-b620-44b5-b181-db43f3d8d37&title=&width=22" alt="image.png">，<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086823787-a9e677a3-621c-4bc1-b2da-a9f7671e1156.png#averageHue=%23d9ba95&clientId=u718981f7-f8e3-4&from=paste&height=20&id=u5383e296&originHeight=20&originWidth=22&originalType=binary&ratio=1&rotation=0&showTitle=false&size=736&status=done&style=none&taskId=u6b46ea0e-5460-4599-b829-70dfe8261ce&title=&width=22" alt="image.png">是最大余弦相似度u和<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086847024-b6ebf592-cd18-4107-b7af-5f3409aa6d44.png#averageHue=%23f7f3ef&clientId=u718981f7-f8e3-4&from=paste&height=19&id=u01a8c6bb&originHeight=19&originWidth=79&originalType=binary&ratio=1&rotation=0&showTitle=false&size=969&status=done&style=none&taskId=u4461398b-0b38-48be-821e-0c07f57d3c7&title=&width=79" alt="image.png">和确保<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086859446-9d9ec35e-474c-4e81-8add-fcd5bc98ec06.png#averageHue=%23e2c398&clientId=u718981f7-f8e3-4&from=paste&height=20&id=uabb2714c&originHeight=20&originWidth=55&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1637&status=done&style=none&taskId=u3dce88d3-e94b-4d5e-93c4-cd5f5f81f76&title=&width=55" alt="image.png">满足对抗的条件。得到<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086869455-c7bd3c64-1a55-47dc-8090-24284ceb39a9.png#averageHue=%23e2c398&clientId=u718981f7-f8e3-4&from=paste&height=20&id=u2719a6cc&originHeight=20&originWidth=55&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1637&status=done&style=none&taskId=uc2eecdeb-9db7-46cd-929b-4b53ac83540&title=&width=55" alt="image.png">后，我们可以按优化顺序生成<img src="https://cdn.nlark.com/yuque/__latex/9ec4b957faa4bd81c9b0ee200f78a1f4.svg#card=math&code=x%27_%7Bt%2B1%7D&id=Wj6sK">。此外，为了减少查询次数和减少扰动率，在实现程序时，我们首先使用x初始化<img src="https://cdn.nlark.com/yuque/__latex/9ec4b957faa4bd81c9b0ee200f78a1f4.svg#card=math&code=x%27_%7Bt%2B1%7D&id=mt7Yd">，然后将单词<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713086818343-8eb2e510-2ce1-4c17-8e92-54cf87eec062.png#averageHue=%23d9ba95&clientId=u718981f7-f8e3-4&from=paste&height=20&id=Fasl8&originHeight=20&originWidth=22&originalType=binary&ratio=1&rotation=0&showTitle=false&size=736&status=done&style=none&taskId=ufdc32f86-b620-44b5-b181-db43f3d8d37&title=&width=22" alt="image.png">逐个替换，直到<img src="https://cdn.nlark.com/yuque/__latex/9ec4b957faa4bd81c9b0ee200f78a1f4.svg#card=math&code=x%27_%7Bt%2B1%7D&id=tGsaF">满足对抗条件。<br />HQA-Attack的详细算法流程在附录B中给出。特别地，HQA-Attack首先通过随机初始化获得初始对抗样本。 然后进入主循环。 在每次迭代，HQA-Attack首先将原始单词替换回去，然后确定优化顺序，最后依次更新对抗样本。 另外，我们还提供了一些机制附录D中从决策边界角度分析HQA-Attack。<br /><strong>Experiments：</strong><br /><strong>数据集：</strong>我们在五个公共文本分类数据集先生，AG的News，Yahoo，Yelp，IMDB，以及三个自然语言推理数据集SNLI，MNLI，mMNLI上进行了实验。详细的数据集描述见附录e。我们按照之前的方法，对每个数据集取1000个测试示例进行实验。<br /><strong>基线：</strong>我们比较了三种最先进的黑盒硬标签文本对抗性攻击方法： (1) HLGA是一种利用遗传算法生成对抗性例子的硬标签对抗性攻击方法。(2)文本Hoaxer是一种硬标签对抗攻击方法，将文本数据的预算硬标签对抗攻击任务定义为连续词嵌入空间中扰动矩阵的梯度优化问题。(3)跳跃攻击是一种最近的硬标签对抗性攻击方法，它通过蒙特卡罗方法来估计梯度。<br /><strong>评估指标：</strong> 我们使用两个广泛使用的评估指标语义相似性和扰动速度。 对于语义相似度，我们利用通用序列编码器[4]来计算语义两个文本之间的相似性。 语义相似度的范围在r0,1s之间，较大者语义相似度表明攻击性能更好。 对于扰动率，我们使用对抗性示例中更改的单词数与总单词数的比率，以及扰动率越低表明结果越好。<br /><strong>受害者模型：</strong>我们采用三种广泛使用的自然语言处理模型作为受害者模型： BERT 、WordCNN和WordLSTM。所有的模型参数都取自之前的作品。我们还攻击了一些高级模型，如T5和DeBERT，结果见附录f。为了进一步验证不同算法在实际应用中的有效性，我们还尝试使用谷歌云API（<a href="https://cloud.google.com/natural-language">https://cloud.google.com/natural-language</a>）和阿里巴巴云API（<a href="https://ai.aliyun.com/nlp">https://ai.aliyun.com/nlp</a>）作为受害者模型。<br /><strong>实施细节：</strong>对于随机初始化，我们采用了与以前的方法相同的方法。在初始化之后，我们按照来执行一个预处理步骤，以删除不必要的替换词。对于超参数，我们始终为所有数据集设置r&#x3D;5和k&#x3D;5。我们的详细参数调查见附录g。此外，在优化过程中，如果我们对相同的敌对例子重新优化三次，并且没有生成新的更好的敌对例子，我们随机回到最后三到四个敌对的例子。我们不会重新优化一个敌对的例子超过两次。为了进行公平的比较，我们通过使用反拟合词向量为每个单词生成50个同义词。我们还进行了基于基于bert的同义词的实验，结果见附录H。<br />我们完全按照前面的工作，将查询预算设置为1000，即攻击者允许的查询数量为1000。由于不同的算法使用相同的随机初始化步骤来决定对抗性攻击后的预测精度，因此不同的算法具有相同的预测精度。我们的目标是生成具有较高语义相似度和较低扰动率的对抗性例子。表2和表3报告了在攻击文本分类模型时的实验结果。最好的结果用粗体突出显示。<br />如表2和表3所示，当查询限制为1000时，对于不同的数据集和任务，HQAAttack总是可以生成具有最高语义相似度和最低扰动率的对抗性示例。具体来说，对于具有短文本数据的数据集，HQA-Attack在攻击BERT、WordLSTM时，平均语义相似度分别提高了6.9%、6.5%、6.9%，平均扰动率降低了0.777%、0.832%、0.983%。对于长文本数据的数据集IMDB，HQA-Attath与攻击BERT、WordCNN和WordLSTM相比，平均语义相似度分别提高了4.5%、3.4%、2.7%，平均扰动率降低了1.426%、0.601%、0.823%。对于AG等两个以上类别的数据集，HQA-Attack在攻击BERT、WordCNN和WordLSTM时，比第二最佳方法的平均语义相似度分别提高了10.6%、8.8%、11.6%，平均扰动率降低了4.785%、3.885%、5.237%。这些结果表明，HQA-攻击可以产生高质量的对抗性攻击。<br />攻击效率是评估攻击性能的一个重要标准，因为在大多数基于DNN的NLP平台中，查询的数量是有限的。因此，我们进一步比较了所提出的HQA攻击在不同查询预算r100、300、500、700、700、1000s下的两种最新方法。如图2所示，随着查询预算的增加，所有方法的平均语义相似度都在不断增加，而所有方法的平均扰动率都在不断下降。在语义相似度和扰动率方面，HQA-Attack在所有预算中都表现得远远优于其他方法。这些结果进一步验证了我们提出的HQA-Attack能够在不同的预算限制下生成具有较高语义相似性和较低扰动率的对抗性例子。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713087533990-bfc9b734-db35-4881-993f-64bf185f072d.png#averageHue=%23f4f1ee&clientId=ub1881779-a13d-4&from=paste&height=565&id=u7b4d3390&originHeight=565&originWidth=720&originalType=binary&ratio=1&rotation=0&showTitle=false&size=130517&status=done&style=none&taskId=uebb0e672-8fda-4448-b1aa-c781872057e&title=&width=720" alt="image.png"><br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713087558778-539bface-3508-4495-896a-7e96bbbb9ad7.png#averageHue=%23f3f0ed&clientId=ub1881779-a13d-4&from=paste&height=198&id=u6a30049f&originHeight=198&originWidth=719&originalType=binary&ratio=1&rotation=0&showTitle=false&size=41888&status=done&style=none&taskId=u4cd09154-2ca7-4733-9e57-89543556a26&title=&width=719" alt="image.png"><br />为了进一步验证不同算法的有效性，我们尝试使用文本攻击器、跳跃攻击和HQA-攻击来攻击两个真实世界的api：谷歌云（<a href="https://cloud.google.com/naturallanguage">https://cloud.google.com/naturallanguage</a>）和阿里巴巴云（<a href="https://ai.aliyun.com/nlp">https://ai.aliyun.com/nlp</a>）。为了进一步评估生成的对抗性例子的流畅性，我们添加了困惑度（PPL）作为额外的评估度量，通过使用GPT-2 Large [31]计算。PPL越低，说明性能越好。由于谷歌和阿里巴巴只提供有限的服务预算，我们从Mr数据集中选择100个长度大于或等于20个单词的示例进行实验，并限制每种方法只能查询API 350次。表4显示了文本攻击器、跳跃攻击和HQA-攻击的结果。可以看出，与第二优结果相比，HQA-Attack分别提高了谷歌云和阿里云的语义相似度5.7%、5.1%，降低了0.062%、0.007%和PPL 9、6。我们还比较了文本攻击器、跳跃攻击和HQA-攻击在不同预算限制下的性能。结果如图3所示。我们可以得到，HQA-Attack在大多数情况下可以具有较高的语义相似度和较低的扰动率，这进一步证明了HQA-Attack优于其他基线。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713087694649-21cf86ed-f278-4a14-9373-05e568805a35.png#averageHue=%23efebe7&clientId=ub1881779-a13d-4&from=paste&height=165&id=uaff4ac91&originHeight=165&originWidth=434&originalType=binary&ratio=1&rotation=0&showTitle=false&size=27860&status=done&style=none&taskId=uc9a4b198-457f-4fc5-a830-fde9e1ec503&title=&width=434" alt="image.png"><br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713087766163-f963b53e-102f-4a52-aa6a-84206c507339.png#averageHue=%23f1efee&clientId=ub1881779-a13d-4&from=paste&height=342&id=u6b7847f7&originHeight=342&originWidth=725&originalType=binary&ratio=1&rotation=0&showTitle=false&size=130842&status=done&style=none&taskId=uaba52fc2-3b54-4d97-9535-7ca41e5b034&title=&width=725" alt="image.png"><br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713087785313-de7f568d-e1b0-410b-b84f-2582f52f3468.png#averageHue=%23f2f0ef&clientId=ub1881779-a13d-4&from=paste&height=218&id=uf6c49ff9&originHeight=218&originWidth=715&originalType=binary&ratio=1&rotation=0&showTitle=false&size=77050&status=done&style=none&taskId=u0699071c-bef0-4958-b871-0ae3237618a&title=&width=715" alt="image.png"><br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713087794972-8a4de1a7-514b-4479-b4c4-ee8f0b7d670a.png#averageHue=%23f2efed&clientId=ub1881779-a13d-4&from=paste&height=122&id=ueb36c271&originHeight=122&originWidth=503&originalType=binary&ratio=1&rotation=0&showTitle=false&size=17976&status=done&style=none&taskId=ub4729a0e-7c22-46cf-a31d-2492b1c3344&title=&width=503" alt="image.png"><br />我们利用Mr和IMDB数据集和HQA攻击数据集对Bert模型进行了人体评估实验。具体来说，对于每个数据集，我们首先随机选择50个原始样本，并使用每种对抗性攻击方法分别生成相应的50个对抗性示例。然后我们让10名志愿者注释这些样本标注类标签，并计算每种方法的平均分类精度（Acc）。直观地说，如果精度更高，这意味着生成的对抗性例子的质量更好。详细的Acc（%）结果如表5所示。结果表明，由HQA-Attack生成的对抗性实例更容易被正确分类，进一步验证了HQA-Attack在保留语义信息方面的优越性。<br />随着人工智能安全的发展，很多工作都集中在对抗性防御上攻击。 我们进一步比较了受害者模型用三种方法训练时的攻击性能有效的对抗训练策略 HotFlip 、SHIELD 和 DNE。 我们选择BERT模型作为受害者模型，将查询预算设置为1000，然后在AG 数据集。 我们还使用困惑度（PPL）作为附加评估指标来判断生成的对抗性示例的流畅性。 表6显示了攻击性能。 我们可以观察到与其他强基线相比，HQA-Attack 也可以获得最好的结果。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713087973236-9f069984-f76f-4727-bf04-f294799c2344.png#averageHue=%23f2efec&clientId=ub1881779-a13d-4&from=paste&height=185&id=u05c1eee8&originHeight=185&originWidth=706&originalType=binary&ratio=1&rotation=0&showTitle=false&size=36065&status=done&style=none&taskId=ua21d26e1-7513-4112-b6a1-0e7b54d9d0f&title=&width=706" alt="image.png"><br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713087997090-ac7e7766-376b-4ce7-8a3b-9933b85e214b.png#averageHue=%23f2efec&clientId=ub1881779-a13d-4&from=paste&height=198&id=u1d0d043a&originHeight=198&originWidth=665&originalType=binary&ratio=1&rotation=0&showTitle=false&size=44202&status=done&style=none&taskId=udf8b206b-fe57-4794-8418-03d5384f110&title=&width=665" alt="image.png"><br />为了研究不同成分的有效性，我们对五个文本进行了消融研究攻击WordCNN 时的分类数据集。 结果如表7所示。随机初始化是指仅通过随机初始化步骤生成的对抗样本。 不带&#x2F;不带替换是指HQA-Attack模型无需替换原词后退一步。w&#x2F;o Optimizing 意味着 HQA-Attack 模型随机选择一个可以保持示例对抗性作为替换，在不优化的情况下将原始单词替换回去对抗性的例子。 很容易发现所有模块都对模型有贡献，这验证了替换原始单词的后退步骤很有用，优化对抗性示例步骤是也是不可或缺的。 为了进一步证明我们提出的单词回替换的有效性我们在附录 I 中添加了一些额外的实验。我们还列出了 HQA-Attack 生成的一些具体对抗示例，如附录 J 所示。这些示例进一步证明了我们提出的 HQA-Attack 模型可以生成高质量的黑盒硬标签对抗模型仅具有小扰动的示例。</p><p><strong>Conclusion：</strong><br />在本文中，我们提出了一种名为HQA-Attack的新方法，以在黑盒硬标签设置中制作高质量的文本对抗性示例。HQAAttack通过替换原词，可以大大降低扰动率。HQA-Attack利用剩余更改词的同义词集对对抗性示例进行优化，可以提高语义相似度，减少查询预算。大量的实验结果表明，所提出的HQA-Attack方法能够生成具有高语义相似度、低扰动率、较少查询数的高质量对抗性实例。在未来的工作中，我们计划尝试更多的优化策略来完善模型，从而进一步提高文本对抗性攻击的性能。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LimeAttack_ Local Explainable Method for Textual Hard-Label Adversarial Attack</title>
      <link href="/2024/04/21/limeattack-local-explainable-method-for-textual-hard-label-adversarial-attack/"/>
      <url>/2024/04/21/limeattack-local-explainable-method-for-textual-hard-label-adversarial-attack/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><strong>Summary：</strong><br />Natural language processing models are vulnerable to adversarial examples. Previous textual adversarial attacks adopt model internal information (gradients or confidence scores) to generate adversarial examples. However, this information is unavailable in the real world. Therefore, we focus on a more realistic and challenging setting, named hard-label attack, in which the attacker can only query the model and obtain a discrete prediction label. Existing hard-label attack algorithms tend to initialize adversarial examples by random substitution and then utilize complex heuristic algorithms to optimize the adversarial perturbation. These methods require a lot of model queries and the attack success rate is restricted by adversary initialization. In this paper, we propose a novel hard-label attack algorithm named LimeAttack, which leverages a local explainable method to approximate word importance ranking, and then adopts beam search to find the optimal solution. Extensive experiments show that LimeAttack achieves the better attacking performance compared with existing hard-label attack under the same query budget. In addition, we evaluate the effectiveness of LimeAttack on large language models and some defense methods, and results indicate that adversarial examples remain a significant threat to large language models. The adversarial examples crafted by LimeAttack are highly transferable and effectively improve model robustness in adversarial training.</p><p><strong>Background：</strong><br />深度神经网络（DNN）广泛应用于自然语言处理领域并取得了巨大成就成功（Kim 2014；Devlin 等人 2019；Minaee 等人 2021；Hochreiter 和Schmidhuber 1997）。 然而，DNN 很容易受到对抗性示例的影响，而这些示例被正确分类样本因一些轻微的扰动而改变（Jin et al. 2020；帕佩诺特等人。 2017年； Kurakin、Goodfellow 和 Bengio 2016）。这些对抗性扰动是人类无法察觉的但可能会误导模型。 严重的对抗性例子威胁 DNN 的鲁棒性和可靠性，尤其是在一些安全关键型应用（例如自动驾驶和有毒文本检测（Yang et al. 2021；Kurakin, Good Fellow 和 Bengio 2018））。 因此，对抗性例子计算机视觉、自然语言处理等领域的对抗性攻击和防御引起了极大的关注演讲（Szegedy 等人，2013 年；Carlini 和 Wagner，2018 年；Yu等人。 2022）。 制作文本对抗性更具挑战性由于语言的离散性质以及词汇、语义和流畅性限制的存在。<br />根据不同场景，进行文本对抗攻击可以简单分为白盒攻击、基于分数的攻击和硬标签攻击。 在白盒设置中，攻击者利用模型的参数和梯度来生成对抗性示例（Goodman、Zhonghou et al. 2020；江等人。 2020）。 基于分数的攻击仅采用类别概率或置信度分数来制作对抗性示例（Jin等人。 2020； 李等人。 2020； 马、史、管2020； 朱，赵和吴 2023）。 然而，由于 DNN 是通过以下方式部署的，这些攻击方法在现实中表现不佳应用程序编程接口（API）和攻击者无法访问模型的参数、所有标签的梯度或概率分布（Ye 等人，2022b）。 相比之下，在硬标签场景下，模型的内部结构，梯度、训练数据甚至置信度分数都是不可用的。 攻击者只能查询黑盒受害者模型并得到离散的预测标签，这更具有挑战性和现实性。 此外，最真实的模型（例如HuggingFace API、OpenAI API）通常有限制关于通话次数。 事实上，对抗性例子攻击设置是带有微小模型查询的硬标签。<br />一些硬标签攻击算法已经被提出（Yu等人。 2022 年； 叶等人。2022b； 马赫什瓦里、马赫什瓦里和普地2021； 叶等人。 2022a）。 他们遵循两阶段策略：i）通过随意用同义词替换几个原始单词来生成低质量的对抗性示例，以及然后 ii) 采用复杂的启发式算法（例如遗传算法）来优化对手的扰动。 所以，这些攻击方法通常需要大量查询，并且攻击成功率和对抗样本的质量是受到对手初始化的限制。 相反，基于分数的攻击根据删除一个单词后置信度分数发生变化。 单词重要性排序通过优先提高攻击效率攻击对模型有重大影响的词预测（Jin 等人，2020）。 然而，基于分数的攻击无法计算硬标签设置中的单词重要性因为删除一个标记几乎不会改变离散预测标签。 因此，我们要研究这样一个问题：如何计算硬标签中的单词重要性排名设置以提高攻击效率？<br />实际上，单词重要性排名可以揭示决策边界以确定更好的攻击路径，但现有的硬标签算法忽略了这些有用的信息因为它很难获得。 受到当地可解释的启发方法（Ribeiro、Singh 和 Guestrin 2016；Lundberg 和李2017; 什里库马尔等人。 2016）对于 DNN，有 10 个用于解释黑盒模型的输出，目标估计良性样本的标记敏感性。 之前的研究（Chai et al. 2023）试图简单地替换基于删除的方法和局部可解释的方法来计算基于分数的攻击中的单词重要性。 然而，在附录B，我们通过实验验证了本地可解释的方法没有显着优势在基于分数的场景中优于基于删除的方法。 因为模型输出的概率分布是可用，每个词对输出的影响可以是基于删除的方法很好地反映了这一点。 因此，与基于分数的攻击相比，我们认为局部可解释方法在硬标签攻击中可以发挥更大的优势基于删除的方法是无用的。 我们采用最多基本且直接的本地可解释方法，即石灰。 LIME 简单易懂，更符合使用基于分数的攻击中提出的基于删除的方法，因为我们的目标是弥合基于分数的攻击之间的差距通过引入可解释性方法来攻击和硬标签攻击。 事实上，局部可解释方法与模型无关，适合对硬标签攻击进行单词重要性估计。 然而，有以下几种情况将 LIME 应用于硬标签攻击的困难：1）如何在极小的查询预算下分配 LIME 和搜索查询以达到最佳效果。 2）如何建立映射在没有模型 Logits 输出的情况下，LIME 与对抗性样本中单词重要性之间的关系。 3) 如何取样在扰动执行期间合理地实现最优结果。 在随后的课程中我们将详细解释如何来解决这些困难。<br /><strong>Contributions：</strong><br />在这项工作中，我们提出了一种新的硬标签攻击算法，称为极限攻击。LIME在硬标签攻击中的应用是受到基于分数的攻击删除方法的启发。我们验证了内外攻击路径在硬标签攻击中的有效性，然后许多优秀的基于分数的攻击可以为硬标签攻击提供更多的见解。为了评估攻击的性能和效率，我们将Lime攻击与其他硬标签攻击进行了比较，并将一些基于分数的攻击作为7个常见数据集上的两个NLP任务的参考。我们还评估了目前最先进的大型语言模型（例如，ChatGPT）的限制eattack。实验表明，在微小的查询预算下，极限攻击比其他基线获得了最高的攻击成功率。我们的贡献总结如下：</p><ul><li>总结了现有硬标签攻击的不足，并应用LIME将分数基攻击与硬标签攻击连接起来，验证了内外攻击路径在硬标签攻击中的有效性。</li><li>大量实验表明，在小预算的查询情况下，有限攻击比现有的硬标签攻击算法具有更高的攻击成功率。与此同时，由极限攻击制作的对抗性例子是高质量的，人类很难区分。</li><li>此外，我们还对当前最先进的大型语言模型进行攻击和评估。结果表明，敌对的例子仍然是对大型语言模型的一个重大威胁。我们还增加了防御方法的攻击性能，以及攻击成功率和扰动率的收敛结果。</li></ul><p><strong>Method：</strong><br /><strong>硬标签对抗性攻击</strong><br />在硬标签设置中，攻击者只能查询受害者模型并获得离散预测标签。 因此，硬标签设置更具实用性和挑战性。 现有的硬标签攻击包含两阶段策略，即对手初始化和扰动优化。 HLBB（Mahesh wary、Maheshwary 和 Pudi 2021）初始化对抗性示例并采用遗传算法来优化扰动。 TextHoaxer（Ye 等人，2022b）和 LeapAttack（Ye 等人，2022b）2022a) 利用语义相似性和扰动率作为优化目标是在连续词嵌入空间中搜索更好的扰动矩阵。 文本黑客（于等人。 2022）采用混合本地搜索算法和单词从攻击历史中学习的重要性表来指导本地搜索。 这些攻击方法往往需要大量的查询降低扰动率，降低攻击成功率对手的质量受到初始化的限制。 因此，在这项工作中，我们尝试制作一个对抗性示例直接来自良性样本。 这种方法可以生成具有更少查询的高质量对抗性示例。<br /><strong>局部可解释方法</strong><br />为了提高 DNN 可解释性并辅助决策，已经提出了各种解释 DNN 的方法并大致分为全局或局部可解释方法。 全局可解释方法侧重于模型本身使用有关模型架构的整体知识和参数。 相反，本地方法适合简单的和可解释模型（例如决策树）到单个输入衡量每个代币的贡献。 详细点，本地可解释的方法（Lundberg 和 Lee 2017；Shrikumar等人。 2016年； ˇStrumbelj 和 Kononenko 2014) 将所有通过定义线性可解释性模型来输入标记假设输入中每个令牌的贡献是添加剂。 这也称为附加特征归因方法。 在本文中，局部可解释模型不可知解释（LIME）（Ribeiro、Singh 和 Guestrin 2016）是用于计算单词重要性，这是一个基本的和代表性的局部可解释方法。 直觉LIME是通过删除来生成很多邻域样本良性示例中的一些原始单词。 这些样品然后用于训练线性模型，其中特征等于良性样本中的单词数。该线性模型的参数近似于每个单词的重要性。 由于 LIME 与模型无关，因此适合硬标签攻击。<br /><strong>现有硬标签攻击的局限性</strong><br />为了直观地比较两者的区别LimeAttack 和现有的硬标签攻击算法，我们创建图 3 中的攻击搜索路径可视化。LimeAt Tack 的搜索路径由绿线表示，它们从内部移动到外部。 LimeAttack 利用本地可解释的方法来学习单词重要性排名，并从良性样本中迭代生成对抗性示例。这有助于 LimeAttack 找到最近的决策边界方向，并且攻击关键字的模型查询成本更少优先。 相比之下，以前的硬标签攻击算法的搜索路径是用蓝线表示的，它们从外向内移动。 这些算法通常从随机初始化的对抗性示例开始，通过最大化初始化示例和良性样本之间的语义相似性来优化扰动，这需要大量的模型查询来实现低扰动速度。 此外，他们的攻击成功率和对手质量也受到对手初始化的限制。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713089503148-356974c7-6793-4ffa-b47b-2595d0e1364d.png#averageHue=%23faf3ef&clientId=u205d476f-211d-4&from=paste&height=317&id=uf37b2f55&originHeight=317&originWidth=440&originalType=binary&ratio=1&rotation=0&showTitle=false&size=38163&status=done&style=none&taskId=u1ca1d600-8c34-40f5-9c3f-e8a1c9127f8&title=&width=440" alt="image.png"><br /><strong>问题公式</strong><br />给定一个n个单词<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713089566228-f284006a-dad0-449a-ab0a-a45d3845ca78.png#averageHue=%23faf8f5&clientId=u205d476f-211d-4&from=paste&height=24&id=ubba0481d&originHeight=24&originWidth=172&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1999&status=done&style=none&taskId=ub8bdf081-f3e5-4d27-bdd6-e3e6747b03e&title=&width=172" alt="image.png">及其地面真相标签Y，一个对立的例子<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713089585703-40d46f49-a711-405e-b0ca-e84cca7a4883.png#averageHue=%23f8f5f1&clientId=u205d476f-211d-4&from=paste&height=21&id=u0d60b16c&originHeight=21&originWidth=168&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2180&status=done&style=none&taskId=u7f630321-5010-4977-a527-082fccb0629&title=&width=168" alt="image.png">是通过用同义词替换一个或多个原始词来误导受害者模型F而制作的。i.e.,<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713089598890-71ad893e-2c77-4b60-8fa5-07f73f5b6fb5.png#averageHue=%23f9f7f4&clientId=u205d476f-211d-4&from=paste&height=31&id=u33818c77&originHeight=31&originWidth=309&originalType=binary&ratio=1&rotation=0&showTitle=false&size=3441&status=done&style=none&taskId=ud5f4e263-62d2-451e-b135-c2d5a738f24&title=&width=309" alt="image.png"><br />D（·，·）是一个编辑距离，测量良性样本<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713089566228-f284006a-dad0-449a-ab0a-a45d3845ca78.png#averageHue=%23faf8f5&clientId=u205d476f-211d-4&from=paste&height=24&id=lfweb&originHeight=24&originWidth=172&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1999&status=done&style=none&taskId=ub8bdf081-f3e5-4d27-bdd6-e3e6747b03e&title=&width=172" alt="image.png">和对抗性例子<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713089585703-40d46f49-a711-405e-b0ca-e84cca7a4883.png#averageHue=%23f8f5f1&clientId=u205d476f-211d-4&from=paste&height=21&id=qKkQB&originHeight=21&originWidth=168&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2180&status=done&style=none&taskId=u7f630321-5010-4977-a527-082fccb0629&title=&width=168" alt="image.png">之间的修改：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713089752208-193d9413-d2c3-41fc-b489-51232e269fef.png#averageHue=%23faf8f6&clientId=u205d476f-211d-4&from=paste&height=58&id=u4a4053c1&originHeight=58&originWidth=225&originalType=binary&ratio=1&rotation=0&showTitle=false&size=4777&status=done&style=none&taskId=u006c5efd-3614-4f1a-8127-4ae494cd5ae&title=&width=225" alt="image.png"><br />E（·，·）是一个二进制变量，如果<img src="https://cdn.nlark.com/yuque/__latex/267af57eb97a3e28c946702f3f0e6246.svg#card=math&code=x_i%3Dx%27_i&id=g80Xh">，则等于0，否则等于1。一个高质量的对抗性例子应该与良性样本相似，人类读者应该很难区分出其区别。极限攻击属于硬标签攻击，它与模型的参数、梯度或置信度分数无关。攻击者只能查询受害者模型，获得预测标签<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713089824738-42310a7c-f7e8-4831-9a24-c1d1eb250170.png#averageHue=%23f4f1ee&clientId=u205d476f-211d-4&from=paste&height=27&id=uc11cb973&originHeight=27&originWidth=88&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2048&status=done&style=none&taskId=u6f44cbcf-b438-43c7-80db-4ffeae02cf8&title=&width=88" alt="image.png">。<br /><strong>所提出的极限攻击算法</strong><br />总体流程图如图2所示。限制攻击遵循两个步骤，即单词的重要性排序和扰动执行。<br /><strong>Word重要性排名</strong><br />给定一个有n个单词X的句子，我们假设所有单词的贡献都是可加性的，并且它们的和与模型的预测呈正相关。如图2所示，我们从一个良性的例子X中随机替换一些单词为‘[MASK]’，生成一些邻域样本<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713089566228-f284006a-dad0-449a-ab0a-a45d3845ca78.png#averageHue=%23faf8f5&clientId=u205d476f-211d-4&from=paste&height=24&id=UnCGN&originHeight=24&originWidth=172&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1999&status=done&style=none&taskId=ub8bdf081-f3e5-4d27-bdd6-e3e6747b03e&title=&width=172" alt="image.png">。通常，有更多单词的句子通常需要更多的邻居样本来近似单词的重要性。因此，我们保持邻域样本的数量与令牌的数量保持一致。然后，我们将X提供给受害者模型F，以获得离散的预测标签<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713089942190-a156e219-6205-4601-aafc-5d2770c73a24.png#averageHue=%23f7f4f0&clientId=u205d476f-211d-4&from=paste&height=27&id=ub95ec821&originHeight=27&originWidth=167&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2482&status=done&style=none&taskId=ua89e5148-c82b-4453-967c-6af1ebb03e2&title=&width=167" alt="image.png">。随后，我们将拟合一个线性可解释性模型来对这些邻域样本进行分类：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713089958222-c5deaa51-10e0-46d2-90d6-50db78767dd6.png#averageHue=%23faf8f6&clientId=u205d476f-211d-4&from=paste&height=55&id=u90c97d9b&originHeight=55&originWidth=241&originalType=binary&ratio=1&rotation=0&showTitle=false&size=4874&status=done&style=none&taskId=u5c560305-9b76-4ce8-9717-e1fa1851581&title=&width=241" alt="image.png"><br />其中θ是线性模型的参数，I（·，·）是一个二进制变量，如果X中的单词xi，则等于1，否则为0。因此，参数<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713090026904-ad91c62b-8bae-451a-a9d5-aa26ddf25c11.png#averageHue=%23fbf8f3&clientId=u205d476f-211d-4&from=paste&height=26&id=u634f4b3b&originHeight=26&originWidth=98&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1920&status=done&style=none&taskId=u63d09a12-0526-478b-b79b-cc80cbf3c6f&title=&width=98" alt="image.png">反映了没有单词xi的变化，并近似于单词的重要性。在附录O中，我们通过实验验证了在微小的查询预算下，线性模型（如LIME）与一些先进的解释方法（如SHAP）或非线性模型（如决策树）具有相同的效果。形状模型或非线性模型也具有较高的计算复杂度。一些先进的解释方法或非线性模型的优势只有在有大量的邻域样本和查询时才会反映出来。<br />详细地说，我们将每个邻域样本Xi‘转换为二进制向量Vi’。如果在Xi‘中去掉了原词，则其在Vi’中对应的向量维数为0，否则为1。因此，Vi‘与Xi’的长度相同，这是良性例子的长度。一个良性的例子X也被转换为V。有时邻域样本不一定是线性可分的，LIME采用高斯核对每个样本的损失进行加权，以收集最接近原始样本的点，这有助于线性拟合。我们根据每个邻域样本与良性样本的距离（Ribeiro，Singh，和Guestrin 2016）给予其权重<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713090101587-0e2294ec-0168-4f1f-a631-f628069723f3.png#averageHue=%23f7f2ed&clientId=u205d476f-211d-4&from=paste&height=24&id=ub8890689&originHeight=24&originWidth=73&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1687&status=done&style=none&taskId=uc93e74b6-f18f-4fd3-8225-15167c29388&title=&width=73" alt="image.png">。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713090087444-0bdee6a4-8fcb-4bdb-a8f9-7d33bc5a5290.png#averageHue=%23f9f6f3&clientId=u205d476f-211d-4&from=paste&height=32&id=u81a7be0c&originHeight=32&originWidth=265&originalType=binary&ratio=1&rotation=0&showTitle=false&size=3770&status=done&style=none&taskId=u45ae6c57-c641-4a96-a6cf-c6384f0f64d&title=&width=265" alt="image.png"><br />其中，d（.，.）是一个距离函数。我们采用余弦相似度作为距离度量。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713090126360-3ae96ce0-daf9-40a1-94f2-385c056216e8.png#averageHue=%23f7f5f3&clientId=u205d476f-211d-4&from=paste&height=59&id=u0edc6481&originHeight=59&originWidth=180&originalType=binary&ratio=1&rotation=0&showTitle=false&size=3380&status=done&style=none&taskId=ub6ecf893-91f6-44fc-92ff-f3a2a8b35df&title=&width=180" alt="image.png"><br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713090162382-abfd654c-15fb-4950-8956-3fc0e80c3edf.png#averageHue=%23f4f1ef&clientId=u205d476f-211d-4&from=paste&height=584&id=ub488e8bf&originHeight=584&originWidth=936&originalType=binary&ratio=1&rotation=0&showTitle=false&size=198011&status=done&style=none&taskId=ucdbe0b13-1cb2-4460-a6d1-8bcc602cd47&title=&width=936" alt="image.png"><br />最后，我们计算了最优参数θ∗：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713090248704-42c4b2c5-7f6a-42f9-a06b-225b72968998.png#averageHue=%23fbf9f7&clientId=u205d476f-211d-4&from=paste&height=60&id=u56fb5f10&originHeight=60&originWidth=392&originalType=binary&ratio=1&rotation=0&showTitle=false&size=8232&status=done&style=none&taskId=ube492b17-2310-4b9a-9aaf-7ac76c3902c&title=&width=392" alt="image.png"><br />其中Ω(θ)是参数的非零，这是对线性模型复杂性的度量。优化θ后，每个单词xi的重要性等于θi。LIME可以看作是原始样本中模型决策边界的近似值。这些参数可以解释为边际，边际越大，这个词在近似决策边界时的重要性就越大。我们将首先使用NLTK2过滤掉停止词，并计算每个单词的重要性。确保极限攻击产生了高质量的对抗性例子，而不仅仅是消极的例子。我们只采用同义词替换策略，通过在反拟合嵌入空间中选择最前k个最近的同义词，为每个单词xi构造同义词候选集C（xi）（Mrkˇsi‘cetal.2016）。此外，我们在附录一中展示了人类评估的结果和更多定性的对抗性例子。<br /><strong>扰动执行</strong> <br />对抗性例子生成是一个组合优化问题。 基于分数的攻击通过选择引起最大变化的标记进行迭代每次都在模型的 logits 中。 但没有这样的信息在硬标签攻击中。因此，我们只能依赖对抗样本与原始样本之间的相似性用于迭代的样本。 问题是相似度和攻击成功率并不完全线性相关。 作为如表7所示，每次贪婪地选择相似度最低的对抗样本并不能保证最终的攻击成功率是最优的。 我们希望每个采样均匀分布以平衡攻击成功率和语义相似度。对于每个起源词xi，我们将其替换为c∈C（xi）来生成一个对抗示例<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713090493904-761cff9e-c1a5-4ea0-b875-1c69645283f1.png#averageHue=%23faf8f5&clientId=u205d476f-211d-4&from=paste&height=23&id=uabb004b0&originHeight=23&originWidth=279&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2621&status=done&style=none&taskId=u54a4893e-92d1-4bdb-aee6-5c4fa9ba869&title=&width=279" alt="image.png">，然后我们计算良性样本X之间的语义相似性通过通用句子编码器（USE）3。我们首先根据相似性对候选对象进行排序，并每次抽样b个对抗性的例子，以进入下一次迭代。详细地说，我们制定了以下采样规则： (1)采样b&#x2F;3个语义相似度最高的对抗性样本。(2)抽样具有语义相似度最低的b&#x2F;3个对抗性样本。(3)随机抽取剩余的敌对性样本中的b&#x2F;3个。附录C和H总结了超参数b的分析和极限攻击算法的分析。</p><p><strong>Experiments：</strong><br />附录D和附件E中列出了对极限攻击的可转移性和对抗性训练的分析。<br /><strong>任务、数据集和模型</strong><br />我们采用了7个常见的数据集，如先生（庞和李2005）、SST-2（Sochere人2013）、AG（张、赵和乐村2015）和雅虎（Yoo等人2020）进行文本分类。SNLI（Bowman等人，2015年）和MNLI（威廉姆斯、Nangia和鲍曼，2018年）的文本含义，其中MNLI包括一个匹配版本（MNLIm）和一个不匹配版本、（MNLImm）。此外，我们还训练了三种神经网络作为受害者模型，包括CNN（Kim，2014年）、LSTM（霍克雷特和施米德胡伯，1997年）和BERT（Devlin等人，2019年）。模型的参数和数据集的详细信息列于附录A中。<br /><strong>基线</strong><br />我们选择以下现有的硬标签攻击算法作为我们的基线：HLBB（Maheshwary、Mahesh wary 和 Pudi 2021）、TextHoaxer（Ye 等人，2022b）、Leap Attack（Ye 等人，2022a）和 TextHacker（Yu 等人，2022）。 此外，我们还收录了一些经典的基于分数的攻击算法，例如TextFooler (TF) (Jin等人。 2020)、PWWS (Ma, Shi, andguan 2020) 和 Bert Attack (Li et al. 2020) 供考，其中获得了额外的攻击的置信度分数并在TextAttack 框架（Morris 等人，2020）。<br /><strong>自动评估指标</strong><br />我们使用四个指标来评估攻击性能：攻击成功率（ASR）、扰动率（Pert）、语义相似度（Sim）和查询数（查询）。具体来说，给定一个数据集<img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713090887348-ece0b49a-2c0c-442f-aea3-72c31f77c1de.png#averageHue=%23f6f2ee&clientId=u205d476f-211d-4&from=paste&height=27&id=u543fb0b5&originHeight=27&originWidth=148&originalType=binary&ratio=1&rotation=0&showTitle=false&size=3357&status=done&style=none&taskId=u4d36c8b9-6ca1-4358-9f69-88d5f4e1bad&title=&width=148" alt="image.png">由N个样本<img src="https://cdn.nlark.com/yuque/__latex/7ca2ff984e95d4a9e44fe7498e281020.svg#card=math&code=X_i&id=yePtF">和相应的标签<img src="https://cdn.nlark.com/yuque/__latex/99f45a182fbbb1d1f79bea448076630f.svg#card=math&code=Y_i&id=A3oMc">，攻击成功率对抗攻击方法，生成对抗的例子(X)给定输入X攻击受害者模型F，定义为（王et al. 2021）：<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713091014421-76e35b59-42c3-44b8-ad2b-f1f6642228b2.png#averageHue=%23f8f7f5&clientId=u205d476f-211d-4&from=paste&height=64&id=uf805e27d&originHeight=64&originWidth=278&originalType=binary&ratio=1&rotation=0&showTitle=false&size=7216&status=done&style=none&taskId=u4c306b06-9552-4437-96d2-cde0b5f8a0e&title=&width=278" alt="image.png"><br />扰动率是替换数与原始token数的比例，这已在Eq 2中定义。语义相似度是通过通用句子编码器（USE）来度量的。大多数论文（马赫什瓦里、马赫什瓦里和普迪，2021年；Ye等人，2022年a）已经采用了USE。为了保持一致性和促进可比性，我们也使用了USE。查询号是在攻击期间的模型查询数。模型的鲁棒性与攻击成功率成反比，而扰动率和语义相似性共同揭示了对抗性例子的质量。查询号显示了攻击的效率。<br /><strong>实施细节</strong><br />我们设置核宽度 σ &#x3D; 25，邻域样本的数量等于良性样本的数量令牌，光束大小 b &#x3D; 10。为了公平比较，所有基线遵循相同的设置：选择同义词来自反向安装的嵌入空间和每个嵌入空间的数量候选集 k &#x3D; 50，同样采样 1000 个文本攻击的基线。 结果是五次运行的平均值不同的种子（1234、2234、3234、4234和5234）来消除随机性。 为了提高对抗质量例如，如果每个的扰动率都相同，则攻击成功对抗性例子不到10%。 我们设置一个小查询硬标签攻击的预算为 100，对应于现实世界的设置。 （例如，HuggingFace 免费推理API 通常将调用次数限制为每分钟 200 次。）<br /><strong>实验结果</strong><br /><strong>攻击性能：</strong>表1和表2显示，Lime攻击在文本分类和文本隐含任务上优于现有的硬标签攻击，在SST-2、AG和MNLI等数据集上获得了更高的攻击成功率和更低的扰动率。与现有的硬标签攻击需要许多查询来优化扰动不同，Lime攻击采用了一种本地可解释的方法来计算单词的重要性排序，并首先攻击关键词。这种方法可以生成具有高攻击成功率的对抗性示例，即使是在很小的查询预算下。附录G包括一个t检验和与其他方法相比的限制攻击的成功率的平均值和方差。在附录K和L中，我们列出了Lime攻击和几种基于分数的攻击之间的语义相似性和比较结果。<br /><strong>查询预算：</strong>如图3所示，在不同的查询预算下，LimeAttatack仍然保持着稳定的攻击成功率和更平滑的攻击曲线，这意味着无论查询预算是高或低，Lime攻击通常都具有稳定和优秀的攻击性能。扰动率的变化趋势见附录n，通过比较低查询和高查询预算下的攻击性能，可以提供更全面的评价。然而，不考虑查询预算的攻击是一种比较理想的情况，它显示了攻击算法的上限。大量的查询是昂贵的，我们认为在低查询预算下的攻击性能更实用。我们还在附录N中列出了在查询预算为2000下的不同攻击的一些攻击成功率和扰动率。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713091435662-5ead375d-6cda-47d8-8c0d-3777862ca7f3.png#averageHue=%23f5f2f1&clientId=u205d476f-211d-4&from=paste&height=322&id=u397ba52f&originHeight=322&originWidth=441&originalType=binary&ratio=1&rotation=0&showTitle=false&size=51809&status=done&style=none&taskId=ue8fc8449-47e3-47e3-8b4e-e9883ac505a&title=&width=441" alt="image.png"><br /><strong>对手的品质</strong>：高质量的对抗样本应该既流畅又具有上下文感知能力，同时也与良性样本相似以逃避人类检测。 我们利用语言工具4并用于检测语法错误并测量语义相似性。 如表3所示，LimeAttack 的扰动率和语法性最低错误，虽然其语义相似度低于HLBB，TextHoaxer 和 LeapAttack。 因为这些方法需要在攻击过程中考虑相似性，因此 LimeAttack与其他方法相比，相似度较低。 考虑到所有指标中，LimeAttack 仍然占据主导地位。 为了直观地比较对抗性例子的质量，一些定性的附录一提供了示例。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713091646301-764732dc-2c27-4257-aaf1-0e9cc6a0250a.png#averageHue=%23f6f4f2&clientId=u205d476f-211d-4&from=paste&height=457&id=ub240c6aa&originHeight=457&originWidth=926&originalType=binary&ratio=1&rotation=0&showTitle=false&size=109203&status=done&style=none&taskId=u2d47fec8-4347-4a31-8835-9c9732a57b2&title=&width=926" alt="image.png"><br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713091662606-c6b96a56-dcc3-4d81-9bcf-3da7ef85f3e4.png#averageHue=%23f3f1ef&clientId=u205d476f-211d-4&from=paste&height=203&id=ua8f425aa&originHeight=203&originWidth=921&originalType=binary&ratio=1&rotation=0&showTitle=false&size=37930&status=done&style=none&taskId=u298c91bb-5ec7-49d6-9924-4423080233c&title=&width=921" alt="image.png"><br /><strong>大型语言模型的评估</strong>：大语言模型（LLM），也称为基础模型（Bom masani et al. 2021），在以下方面取得了令人印象深刻的表现各种自然语言处理任务。 然而，它们对对抗性例子的鲁棒性仍不清楚（Wang 等人，2023）。 为了评估 LimeAttack 对法学硕士的有效性，我们选择了一些流行的型号，例如DeBERTa-L（Kojima等人。 2022）、BART-L（Lewis 等人，2019）、Flan-T5（Raffel<br />等人。 2020)、GPT-3 (text-davinci-003) 和 ChatGPT (gpt-3.5-turbo）（Brown 等人，2020）。 由于API调用有限，我们从 MR 数据集中抽取 100 个文本，并攻击这些模型的零样本分类任务。 如表4所示，LimeAttack 成功攻击了大多数 LLM查询预算。 尽管这些模型具有很高的准确度零样本任务，它们对对抗性例子的鲁棒性仍然需要改进。 ChatGPT 和 T5-L 更稳健到对抗性的例子。 受害者模型的稳健性与原点精度有关。 原点精度越高，受害者模型防御对抗性的能力越强例子。 其他硬标签攻击的进一步分析和实验细节在附录 F 中讨论。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713091808204-eb27f06c-02a7-4cf5-8fb6-e9f3dc093fc6.png#averageHue=%23f4f1ee&clientId=u205d476f-211d-4&from=paste&height=232&id=ue3d4842e&originHeight=232&originWidth=438&originalType=binary&ratio=1&rotation=0&showTitle=false&size=42045&status=done&style=none&taskId=u5e6b5a6c-2642-4fa4-947f-58f54f56f9d&title=&width=438" alt="image.png"><br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713091828619-ca845d9a-d512-4d3a-8cbd-728f53a43111.png#averageHue=%23f3f0ed&clientId=u205d476f-211d-4&from=paste&height=239&id=ue9662c52&originHeight=239&originWidth=454&originalType=binary&ratio=1&rotation=0&showTitle=false&size=47878&status=done&style=none&taskId=u65e74b4c-485f-4a99-a2a7-7ffa0924bb6&title=&width=454" alt="image.png"><br /><strong>对防御方法的攻击性能</strong> <strong>：</strong>评估LimeAttack 对防御方法的有效性，我们使用 A2T（Yoo 和 Qi 2021）和 ASCC（Dong 等人，2021）增强BERT对SNLI的防御能力，并在此基础上进行了攻击实验。 如表5所示，LimeAttack仍然有一定的攻击效果和结果这些防御方法的其他基线。 更多攻击性能防御方法列于附录M。<br /><strong>消融研究</strong><br /><strong>单词重要性排名的影响</strong>： 为了验证单词重要性排序的有效性，我们删除了单词重要性排名策略，而是随机选择单词进行扰动以评估其有效性。 表6表明在没有单词重要性排名的情况下，攻击MR 和 SST 的成功率分别下降 9% 和 6%分别是2个数据集。 此外，对抗性例子随机选择产生的扰动率更高并需要更多查询。 这表明了重要性引导 LimeAttack 聚焦的单词重要性排名关键词，以更低的成本实现更有效的攻击扰动率。<br /><strong>抽样规则的效果：</strong>为了验证LimeAttack抽样规则的有效性，我们将用三种常见的抽样规则之一替换该策略： (1)选择b个语义相似度最高的对抗性例子，(2)选择b个语义相似度最低的对抗性例子，或(3)随机选择b个对抗性例子。表7的结果表明，Lime攻击具有较高的攻击成功率和较低的扰动率，优于其他采样规则。此外，它还具有类似的（第二高的）语义相似度和查询的数量。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713092061432-882bf24a-ce46-4896-998d-39180f92b8d6.png#averageHue=%23f3f1ee&clientId=u205d476f-211d-4&from=paste&height=245&id=u64e506cb&originHeight=245&originWidth=436&originalType=binary&ratio=1&rotation=0&showTitle=false&size=36528&status=done&style=none&taskId=ucbb7b4ad-4705-474e-ae06-ab3d97a3cee&title=&width=436" alt="image.png"><br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713092116737-7ecb9243-d233-411d-a08b-0e126a018fd3.png#averageHue=%23f1eeeb&clientId=u205d476f-211d-4&from=paste&height=188&id=uad4f31ca&originHeight=188&originWidth=434&originalType=binary&ratio=1&rotation=0&showTitle=false&size=36376&status=done&style=none&taskId=uaa889d5d-52d4-441f-8624-203e2d99f0d&title=&width=434" alt="image.png"><br /><strong>人工评价</strong><br />我们选择了 200 个 BERT-MR 对抗样本。 每个对抗性例子都由两名人类评委进行评估语义相似度、流畅度和预测准确性。 这整个人类评价与TextFooler一致（Jin等人。 2020）。 具体来说，我们要求人类评委打出 5 分Likart 量表（1-5 对应于非常不流利&#x2F;相似，不流畅&#x2F;相似、不确定、流畅&#x2F;相似、非常流畅&#x2F;相似分别）评价相似度和流畅度对抗性样本和良性样本。 结果是如表8所示，语义相似度为4.5，即对抗样本与原始样本相似。 这里的预测准确度是让人类能够预测出什么这句话的标签是（例如它是肯定的还是否定的情绪分析）。 76.7% 表示大多数是敌对的示例与原始样本具有相同的属性人类的视角却错误的受害者模型。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713092190675-cb5217ff-9c97-46da-82f8-db28f57b260a.png#averageHue=%23f4f2ef&clientId=u205d476f-211d-4&from=paste&height=197&id=u465ca341&originHeight=197&originWidth=440&originalType=binary&ratio=1&rotation=0&showTitle=false&size=29130&status=done&style=none&taskId=u303469a4-60da-418b-92e9-7157ee63aa0&title=&width=440" alt="image.png"></p><p><strong>Conclusion：</strong><br />在本工作中，我们总结了以往基于分数的攻击和硬标签攻击，并提出了一种新的硬标签攻击算法，称为极限攻击。极限攻击采用一种局部可解释的方法来近似计算单词的重要性排序，然后利用波束搜索，以微小的查询预算生成高质量的对抗性示例。实验表明，极限攻击的攻击成功率高于其他硬标签攻击的攻击成功率。此外，我们还评估了极限攻击在大型语言模型和一些防御方法上的攻击性能。极限攻击所制作的对抗性实例具有高质量、高可转移性，提高了受害者模型在对抗性训练中的鲁棒性。极限攻击已经验证了在硬标签中的内外攻击路径的有效性。然后，许多优秀的基于分数的攻击可能会提供更深入的硬标签攻击。<br /><img src="https://cdn.nlark.com/yuque/0/2024/png/39032054/1713092296864-9ec93680-63f3-4d96-ae06-563e05772e54.png#averageHue=%23f1eeec&clientId=u205d476f-211d-4&from=paste&height=177&id=u584b228d&originHeight=177&originWidth=863&originalType=binary&ratio=1&rotation=0&showTitle=false&size=36445&status=done&style=none&taskId=u2d9bd364-082b-4af1-ae11-75568da0b57&title=&width=863" alt="image.png"></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
